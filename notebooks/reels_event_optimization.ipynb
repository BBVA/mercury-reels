{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a24c8a-dede-4658-bccd-0db87cff718b",
   "metadata": {},
   "source": [
    "# REELS: Event optimizer\n",
    "\n",
    "<img style=\"float: right;\" src=\"images/piece-puzzle.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3cd287-84f8-48d5-b47a-104fb0830de3",
   "metadata": {},
   "source": [
    "## Event Optimization Overview\n",
    "\n",
    "This notebook explores how to optimize event representations in `reels` to improve model performance and interpretability. You will learn how to:\n",
    "\n",
    "* Control event discovery using configuration parameters\n",
    "* Reduce high-cardinality event spaces\n",
    "* Evaluate the impact of different event settings on model performance\n",
    "* Compare optimized and non-optimized configurations\n",
    "\n",
    "The goal is to show how thoughtful event design can significantly influence both predictive quality and model structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778cd2b4-a293-450f-979a-43ffc3c7d780",
   "metadata": {},
   "source": [
    "## What is Event Optimization?\n",
    "\n",
    "In `reels`, event optimization refers to the process of refining how raw event codes are represented before model training. Real-world datasets often contain thousands of distinct event codes, many of which are sparse, redundant, or weakly informative.\n",
    "\n",
    "Event optimization reduces this high-cardinality space by:\n",
    "\n",
    "* Limiting the maximum number of discovered events\n",
    "* Selecting the most informative codes\n",
    "* Aggregating or pruning infrequent events\n",
    "\n",
    "The result is a more compact and balanced event representation, which can improve model stability, interpretability, and predictive performance while reducing noise introduced by rare or random codes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51496d5b-babc-45be-ad69-1e5ae66f619e",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "<img style=\"float: left;\" src=\"images/reels_small.png\"> You should complete the **reels_walkthrough** tutorial before starting with this one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb2c80-55e0-4273-86df-ba874e922a8c",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will use some standard packages in this notebook that we include here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81db30db-071c-450d-a5d9-c63a2bed201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time, io\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0b29a-ed11-4ebe-b00d-53b8f25d6d8c",
   "metadata": {},
   "source": [
    "Now, we import reels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79e7af0-9ac6-41b3-ad02-bc10fc2e4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea1aee-d4da-44e0-b812-c18e8147df17",
   "metadata": {},
   "source": [
    "Additionally, we can verify that we are using the right version. (This notebook requires at least version 1.3.1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ac35a4-e588-409d-9ea9-fa9d188891be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reels.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab33474-96c4-4c32-9533-d28df463adfa",
   "metadata": {},
   "source": [
    "## The problem Event Optimization solves!\n",
    "\n",
    "Real datasets possibly have hundreds of millions of transactions, millions of clients and thousands of event codes. Reels usually works just fine in those conditions.\n",
    "\n",
    "On top of that, there may be additional complications:\n",
    "\n",
    "  - Sequences for each client are typically very long (over 100 events).\n",
    "  - We want to predict a target that is extremely unbalanced, like in fraud applications where only 1 in 10,000 clients are targets.\n",
    "\n",
    "Fitting the data will result in way too many sequences being seen just once in the dataset. That will result in extreme overfitting to the point that the model will be of very limited use when applied to unseen data. \n",
    "\n",
    "### What is the \"magical solution\" to that?\n",
    "\n",
    "In these conditions, we will typically fit the model with the `as_states` argument of `Targets.fit()` set to true. If, rather than having 30,000 event codes, we could \n",
    "\"magically\" select the 20 codes that are relevant to predicting the target and assign a dummy code to all the rest, we would benefit from both:\n",
    "\n",
    "  - The sequences becoming much shorter (as states)\n",
    "  - The sequences being much less unique\n",
    "  \n",
    "That produces a much smaller tree with many more visits per node that will generalize much better to unseen data.\n",
    "\n",
    "### What is the \"practical solution\" to that?\n",
    "\n",
    "Needless to say, it is hard to \"magically\" find **the 20** codes. When we limit the discovery of codes by setting the `max_num_events` argument when constructing `Events` objects, we are only limiting the event to the most **frequently seen** in the dataset, **not necessarily relevant** to any prediction.\n",
    "\n",
    "The good news is: we may find a set of 200 codes that includes 15 of them that works almost as well as the \"perfect\" fit.\n",
    "\n",
    "And we can do that, if we are lucky, by calling an automatic search with default parameters. More likely, it will happen using the tools the **event optimizer** provides to better understand the problem and manually including and excluding sets of codes from the model.\n",
    "\n",
    "### The quest for \"The Dictionary\"\n",
    "\n",
    "Summarizing, we want to find a dictionary that maps thousands of codes in an **Events** object into tens of relevant codes.\n",
    "\n",
    "This notebook provides examples to understand how to discover and apply that dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ad3c0-88a5-41c1-b15d-0f062f08d1c3",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "This synthetic dataset is \"loosely based\" on a real BBVA web navigation dataset. The original dataset cannot be used in the tutorial for compliance and practical considerations.\n",
    "\n",
    "This synthetic dataset is smaller, simpler and much less unbalanced than the original one. Therefore, it works much better \"out of the box\". Nonetheless, it does improve somewhat with event optimization and, because it is not so easy to auto detect the signal, provides a good basis to understand manual intervention on the optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb36a0c-c1c6-4c0d-aac9-f8a28b331ccd",
   "metadata": {},
   "source": [
    "The following code defines the function `create_datasets()` that uses a Clips object to read the test sequences from it and modifies them at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd6dc82-39cc-4771-abb8-b5faa3efc26d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_chunk(seq, cli, time_ori, max_delay):\n",
    "\tN = len(seq)\n",
    "\n",
    "\temi    = ['click' for _ in range(N)]\n",
    "\tweight = [1 for _ in range(N)]\n",
    "\tclient = [cli for _ in range(N)]\n",
    "\ttimes  = []\n",
    "\tct = time_ori\n",
    "\n",
    "\tfor _ in range(N):\n",
    "\t\tct += random.random()*max_delay\n",
    "\t\ttimes.append(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ct)))\n",
    "\n",
    "\treturn pd.DataFrame(list(zip(emi, seq, weight, client, times)), columns = ['emitter', 'description', 'weight', 'client', 'time'])\n",
    "\n",
    "\n",
    "def modify_chunk(chunk, cli, reduce, mutate):\n",
    "\tN = chunk.shape[0]\n",
    "\n",
    "\tif N > 5:\n",
    "\t\tchunk = chunk.sample(frac = reduce, replace = False)\n",
    "\t\tN = chunk.shape[0]\n",
    "\n",
    "\tchunk.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\tfor _ in range(random.randrange(1, round(2 + mutate*N))):\n",
    "\t\ti = random.randrange(0, N)\n",
    "\t\tj = random.randrange(0, N)\n",
    "\t\tx = chunk.description.at[i] + 1\n",
    "\t\tchunk.description.at[i] = chunk.description.at[j]\n",
    "\t\tchunk.description.at[j] = x\n",
    "\n",
    "\tchunk.client = [cli for _ in range(N)]\n",
    "\n",
    "\treturn chunk\n",
    "\n",
    "\n",
    "def create_datasets(test = False, n_extra = 10, reduce = 0.95, mutate = 0.15):\n",
    "\n",
    "\tevents  = reels.Events()\n",
    "\tclients = reels.Clients()\n",
    "\tclips   = reels.Clips(clients, events)\n",
    "\n",
    "\tchunks = []\n",
    "\ttargs  = None\n",
    "\n",
    "\ttime_ori  = time.mktime(time.strptime('2022-06-01 00:00:01', '%Y-%m-%d %H:%M:%S'))\n",
    "\tmax_delay = 3600\n",
    "\n",
    "\tif test:\n",
    "\t\ti_base = 400\n",
    "\t\ti_top  = 500\n",
    "\telse:\n",
    "\t\ti_base = 0\n",
    "\t\ti_top  = 400\n",
    "\n",
    "\tfor i_cli in range(i_base, i_top):\n",
    "\t\tseq = clips.test_sequence(i_cli, False)\n",
    "\n",
    "\t\tcli = 'n%04i%03i' % (i_cli, 0)\n",
    "\n",
    "\t\tchunk = build_chunk(seq, cli, time_ori, max_delay)\n",
    "\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tfor t in range(1, n_extra):\n",
    "\t\t\tcli\t  = 'n%04i%03i' % (i_cli, t)\n",
    "\t\t\tchunk = modify_chunk(chunk, cli, reduce, mutate)\n",
    "\t\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tseq = clips.test_sequence(i_cli, True)\n",
    "\n",
    "\t\tcli = 't%04i%03i' % (i_cli, 0)\n",
    "\n",
    "\t\tchunk = build_chunk(seq, cli, time_ori, max_delay)\n",
    "\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tct = time.mktime(time.strptime(chunk.time.iloc[-1], '%Y-%m-%d %H:%M:%S'))\n",
    "\t\tct += random.random()*max_delay\n",
    "\t\tct -= random.random()*max_delay\n",
    "\n",
    "\t\tchunk = pd.DataFrame([[cli, time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ct))]], columns = ['client', 'time'])\n",
    "\t\ttargs = chunk if targs is None else pd.concat([targs, chunk])\n",
    "\n",
    "\treturn pd.concat(chunks), targs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f5b907-b165-43f4-86b6-8058d03c559a",
   "metadata": {},
   "source": [
    "## A simple analysis\n",
    "\n",
    "We also copy from the **reels_walkthrough** tutorial the function `analyze()` that will serve to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e88e05-11e0-4b25-af7b-6b96079a9d43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze(targets, clips, targs):\n",
    "    target_hashes = set([clients.hash_client_id(str(id)) for id in targs.client])  # This is the set of all the clients who are targets\n",
    "    Y_obs = [int(hh in target_hashes) for hh in clips.clips_client_hashes()]       # This is the observed target/no_target for all the clients\n",
    "    \n",
    "    T = [t for t in targets.predict_clips(clips)]                                  # These are the predicted times\n",
    "    \n",
    "    t_copy = T.copy()\n",
    "    t_copy.sort()\n",
    "    t_cut = t_copy[sum(Y_obs)]                                                     # t_cut is a cutting time that generates the same number of targets.\n",
    "    \n",
    "    Y_pred = [int(t <= t_cut) for t in T]                                          # This is the predicted target/no_target for all the clients\n",
    "    \n",
    "    x_tab = pd.crosstab(pd.array(Y_obs), pd.array(Y_pred), rownames = ['Obs'], colnames = ['Pred'])\n",
    "    \n",
    "    acc    = metrics.accuracy_score(Y_obs, Y_pred)                                 # We compute basic metrics\n",
    "    prec   = metrics.precision_score(Y_obs, Y_pred)\n",
    "    f1     = metrics.f1_score(Y_obs, Y_pred)\n",
    "\n",
    "    print(x_tab)\n",
    "    print('Accuracy: %.3f, precision: %.3f, f1-score: %.3f' % (acc, prec, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1eb6ad-e805-41c6-bb41-34eb33ee3fff",
   "metadata": {},
   "source": [
    "We create the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b336cb1-da38-444e-ab1b-b0ce0f85b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targs = create_datasets(False)\n",
    "test,  test_targs  = create_datasets(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7681ccad-c997-4a30-9ba0-c56254f0b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emitter</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "      <th>client</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>click</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 00:45:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>click</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 01:27:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>click</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 01:35:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>click</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 01:59:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>click</td>\n",
       "      <td>864</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 02:38:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 06:56:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 07:53:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 08:12:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 08:40:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>click</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 09:25:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139783 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   emitter  description  weight    client                 time\n",
       "0    click            1       1  n0000000  2022-06-01 00:45:29\n",
       "1    click           17       1  n0000000  2022-06-01 01:27:22\n",
       "2    click           92       1  n0000000  2022-06-01 01:35:07\n",
       "3    click          227       1  n0000000  2022-06-01 01:59:50\n",
       "4    click          864       1  n0000000  2022-06-01 02:38:04\n",
       "..     ...          ...     ...       ...                  ...\n",
       "14   click          459       1  t0399000  2022-06-01 06:56:36\n",
       "15   click          459       1  t0399000  2022-06-01 07:53:54\n",
       "16   click          459       1  t0399000  2022-06-01 08:12:40\n",
       "17   click          459       1  t0399000  2022-06-01 08:40:08\n",
       "18   click          462       1  t0399000  2022-06-01 09:25:52\n",
       "\n",
       "[139783 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644a8a6a-8c88-4124-9a99-c44a7c306f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0000000</td>\n",
       "      <td>2022-06-01 15:49:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0001000</td>\n",
       "      <td>2022-06-01 23:37:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0002000</td>\n",
       "      <td>2022-06-01 03:36:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0003000</td>\n",
       "      <td>2022-06-01 18:36:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0004000</td>\n",
       "      <td>2022-06-01 04:13:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0395000</td>\n",
       "      <td>2022-06-01 08:47:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0396000</td>\n",
       "      <td>2022-06-02 10:22:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0397000</td>\n",
       "      <td>2022-06-01 02:55:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0398000</td>\n",
       "      <td>2022-06-02 12:17:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 09:17:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      client                 time\n",
       "0   t0000000  2022-06-01 15:49:23\n",
       "0   t0001000  2022-06-01 23:37:44\n",
       "0   t0002000  2022-06-01 03:36:12\n",
       "0   t0003000  2022-06-01 18:36:42\n",
       "0   t0004000  2022-06-01 04:13:49\n",
       "..       ...                  ...\n",
       "0   t0395000  2022-06-01 08:47:12\n",
       "0   t0396000  2022-06-02 10:22:26\n",
       "0   t0397000  2022-06-01 02:55:59\n",
       "0   t0398000  2022-06-02 12:17:13\n",
       "0   t0399000  2022-06-01 09:17:49\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e5ccc-8953-45b3-b1c4-96eae68b44f7",
   "metadata": {},
   "source": [
    "And now, we perform a very simple cross-validated fit/predict as we learned in the **reels_walkthrough** tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8502bc31-a710-4f25-971b-e0a2ac2c6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "intake_train       = reels.Intake(train)\n",
    "intake_train_targs = reels.Intake(train_targs)\n",
    "intake_test        = reels.Intake(test)\n",
    "intake_test_targs  = reels.Intake(test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab82fd-9a8c-4f53-aa2b-5cd46bb3547e",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426209b3-659c-415c-9b80-90068911c79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Events object with 1968 events"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = reels.Events(max_num_events = 10000)\n",
    "\n",
    "intake_train.insert_rows(events)\n",
    "intake_test.insert_rows(events)\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d291e74-7ead-48b4-96d6-969023c29442",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9900535-1bbe-4edc-92ad-b0997ad23b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty reels.Clients object (Empty objects select ALL clients.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = reels.Clients()\n",
    "\n",
    "clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876308e-b6d5-43b0-891f-d9bf885ddb64",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a82854c-3b9c-49e3-bf3a-4e7c1a3d8484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 4130 clips totalling 138716 events"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clips = reels.Clips(clients, events)\n",
    "intake_train.scan_events(train_clips)\n",
    "\n",
    "train_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6948f-f6d4-4195-8d20-10c14aac4d63",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2677cf-0498-4866-89a5-83673b0def26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Targets object with 4130 clips\n",
       "\n",
       "Has 400 targets.\n",
       "\n",
       "Is fitted with 4129 clips."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = reels.Targets(train_clips)\n",
    "intake_train_targs.insert_targets(targets)\n",
    "targets.fit(agg = 'longest', depth = 100, as_states = True)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d612c86-41f6-4e87-ab13-84f8afa9af50",
   "metadata": {},
   "source": [
    "We evaluate the prediction over the **training set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81edaf5-3c8a-4fad-b74d-09a754f5f7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0    1\n",
      "Obs            \n",
      "0     3567  163\n",
      "1      162  238\n",
      "Accuracy: 0.921, precision: 0.594, f1-score: 0.594\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, train_clips, train_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101a54c-71dd-4486-a3ab-1e82a0dfae47",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e9f68f-d5e6-4d4c-be3a-f6759286b52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 1037 clips totalling 30812 events"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clips = reels.Clips(clients, events)\n",
    "intake_test.scan_events(test_clips)\n",
    "\n",
    "test_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6ef7-287f-482b-8ea5-4d88a7300d0c",
   "metadata": {},
   "source": [
    "And evaluate the prediction over the **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9c50e30-72dc-438a-ac26-bcdc833389bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred    0   1\n",
      "Obs          \n",
      "0     860  77\n",
      "1      72  28\n",
      "Accuracy: 0.856, precision: 0.267, f1-score: 0.273\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, test_clips, test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c685d-7875-41cb-94d3-2345fc10e58b",
   "metadata": {},
   "source": [
    "## Event Optimization\n",
    "\n",
    "So far, we have trained a rather good model that performs worse on test data, just as expected.\n",
    "\n",
    "We can also check some statistics about the nodes of the fitted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd1fbba-ec83-45ab-aa5e-cea3f96c8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree.size() : 95158\n",
      "\n",
      "num_of_nodes_with_zero_visits : 0\n",
      "num_of_no_targets_one_visit   : 79616\n",
      "num_of_has_target_one_visit   : 10009\n",
      "num_of_no_targets_more_visits : 5121\n",
      "num_of_has_target_more_visits : 412\n",
      "num_of_no_targets_final_node  : 3700\n",
      "num_of_has_target_final_node  : 373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(targets.describe_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42fa5e-9d7b-4f37-8daa-e2830047d287",
   "metadata": {},
   "source": [
    "As we would expect, it has many nodes with only one visit and is somewhat unbalanced (about 8:1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf84e4c-45dd-4aa1-9f6f-4d2a5de82d56",
   "metadata": {},
   "source": [
    "In case the original data provides some business insight to us, since we assume the codes are just meaningless numbers,\n",
    "we are going to build a simple dictionary mapping the content to the code. In this case, we map the field `description` (that in our example contains just numbers, but could have been descriptive text.)\n",
    "\n",
    "Later we will add a column to our code exploration dataset using this.\n",
    "\n",
    "This can be done by just iterating through the object via `describe_events()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2981ff36-41da-4869-9427-1d310b6ce173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "description = {}\n",
    "for emitter, descr, weight, code in events.describe_events():\n",
    "    description[code] = descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687a09c-6b0d-4c8c-a7b7-7d7bf176ba46",
   "metadata": {},
   "source": [
    "Now, we make a copy of the events dataset and optimize the copy, since the optimization will alter the object and we are just running it to get some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17fe0299-fa0f-4c5d-9b94-4da56d16f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_copy = events.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fddf0-531a-49e1-bd8e-4c806a125e87",
   "metadata": {},
   "source": [
    "Now we run the `optimize_events()` method, just for one iteration and removing exponential decay and the confidence interval.\n",
    "\n",
    "The **exponential decay** is a parameter that allows weighting the score of a code less as it is found deeper in the tree.\n",
    "\n",
    "The **confidence interval** is computed exactly like in `Targets().fit()` and allows computing lift based on the lower bound of a binomial confidence interval for a proportion rather than the proportion itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e6bd37-821a-48f9-b7b3-1a3732c2401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, dictionary, top_codes, log = events_copy.optimize_events(train_clips, targets, num_steps = 1, exp_decay = 0, lower_bound_p = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fc1ec-3414-43df-b348-9968a1e92c10",
   "metadata": {},
   "source": [
    "It returns a tuple of 4 elements:\n",
    "\n",
    " 1. the dictionary that we are not going to use yet, \n",
    " 2. a boolean that is true on success,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21447c77-3a0d-4b41-a01b-f6dcb25b9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d89fd5-56e0-4527-85ba-fc6b2de6be30",
   "metadata": {},
   "source": [
    " 3. a log saved as a string giving us some idea about how the search went,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80c41fb3-0c06-44e5-adad-2a84a0ccf8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing:\n",
      "\n",
      "  1829 codes found in clips.\n",
      "  139 codes removed from internal EventMap.\n",
      "  Current score = 0.845005\n",
      "\n",
      "Step 1 of 1\n",
      "\n",
      "  Trying:\n",
      "    Code 1740 as 2\n",
      "    Code 1690 as 3\n",
      "    Code 1638 as 4\n",
      "    Code 1366 as 5\n",
      "    Code 1456 as 6\n",
      "    ---------------\n",
      "    Score = 0.075123\n",
      "    Best score so far.\n",
      "\n",
      "== F I N A L ==\n",
      "\n",
      "  Final score      = 0.075123\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562c530-e80e-49c5-a429-049d9819fdfd",
   "metadata": {},
   "source": [
    " 4. and `top_codes`, a dataframe (in csv format) with the performance of each code.\n",
    "    \n",
    "We convert it into a pandas dataframe by passing the string to `pd.read_csv()` using an `io.StringIO` and sort it by the column `n_incl_target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "830b0479-1131-4ba3-aafd-a7cb1b3f6a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_succ_seen</th>\n",
       "      <th>n_succ_target</th>\n",
       "      <th>n_incl_seen</th>\n",
       "      <th>n_incl_target</th>\n",
       "      <th>sum_dep</th>\n",
       "      <th>n_dep</th>\n",
       "      <th>edf</th>\n",
       "      <th>prop_succ</th>\n",
       "      <th>prop_incl</th>\n",
       "      <th>lift</th>\n",
       "      <th>score</th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22378</td>\n",
       "      <td>2600</td>\n",
       "      <td>15472</td>\n",
       "      <td>2030</td>\n",
       "      <td>596335</td>\n",
       "      <td>13151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116186</td>\n",
       "      <td>0.131205</td>\n",
       "      <td>0.755779</td>\n",
       "      <td>0.099162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14563</td>\n",
       "      <td>1797</td>\n",
       "      <td>6877</td>\n",
       "      <td>1022</td>\n",
       "      <td>254176</td>\n",
       "      <td>5881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123395</td>\n",
       "      <td>0.148611</td>\n",
       "      <td>0.790435</td>\n",
       "      <td>0.117468</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11953</td>\n",
       "      <td>1364</td>\n",
       "      <td>5076</td>\n",
       "      <td>654</td>\n",
       "      <td>140533</td>\n",
       "      <td>4067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114114</td>\n",
       "      <td>0.128842</td>\n",
       "      <td>0.755683</td>\n",
       "      <td>0.097363</td>\n",
       "      <td>20</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16877</td>\n",
       "      <td>1452</td>\n",
       "      <td>8851</td>\n",
       "      <td>549</td>\n",
       "      <td>374802</td>\n",
       "      <td>7635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086034</td>\n",
       "      <td>0.062027</td>\n",
       "      <td>0.542880</td>\n",
       "      <td>0.033673</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10761</td>\n",
       "      <td>1128</td>\n",
       "      <td>3127</td>\n",
       "      <td>310</td>\n",
       "      <td>124557</td>\n",
       "      <td>2818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104823</td>\n",
       "      <td>0.099137</td>\n",
       "      <td>0.665649</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>17</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>4129</td>\n",
       "      <td>399</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>513</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>514</td>\n",
       "      <td>2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>4822</td>\n",
       "      <td>496</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>524</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>4226</td>\n",
       "      <td>421</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.099621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>525</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1762</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1829 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_succ_seen  n_succ_target  n_incl_seen  n_incl_target  sum_dep  n_dep  \\\n",
       "0           22378           2600        15472           2030   596335  13151   \n",
       "1           14563           1797         6877           1022   254176   5881   \n",
       "2           11953           1364         5076            654   140533   4067   \n",
       "3           16877           1452         8851            549   374802   7635   \n",
       "4           10761           1128         3127            310   124557   2818   \n",
       "...           ...            ...          ...            ...      ...    ...   \n",
       "1824         4129            399            1              0        1      1   \n",
       "1825            2              0            2              0       16      2   \n",
       "1826         4822            496           19              0      531     18   \n",
       "1827         4226            421           14              0      245     13   \n",
       "1828            7              0            7              0       75      5   \n",
       "\n",
       "      edf  prop_succ  prop_incl      lift     score  code description  \n",
       "0     1.0   0.116186   0.131205  0.755779  0.099162     1           1  \n",
       "1     1.0   0.123395   0.148611  0.790435  0.117468     2          17  \n",
       "2     1.0   0.114114   0.128842  0.755683  0.097363    20         349  \n",
       "3     1.0   0.086034   0.062027  0.542880  0.033673    10           2  \n",
       "4     1.0   0.104823   0.099137  0.665649  0.065990    17         350  \n",
       "...   ...        ...        ...       ...       ...   ...         ...  \n",
       "1824  1.0   0.096634   0.000000  0.000000  0.000000   513        2218  \n",
       "1825  1.0   0.000000   0.000000  0.000000  0.000000   514        2219  \n",
       "1826  1.0   0.102862   0.000000  0.000000  0.000000   524         238  \n",
       "1827  1.0   0.099621   0.000000  0.000000  0.000000   525         343  \n",
       "1828  1.0   0.000000   0.000000  0.000000  0.000000  1762         878  \n",
       "\n",
       "[1829 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = pd.read_csv(io.StringIO(top_codes), sep = '\\t')\n",
    "top['description'] = [description[c] for c in top.code]\n",
    "top.sort_values(by = 'n_incl_target', ascending = False, inplace = True)\n",
    "top.reset_index(drop = True, inplace = True)\n",
    "\n",
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5674b-1cdd-47d1-9c14-2f5209e94e56",
   "metadata": {},
   "source": [
    "NOTE: We have added the field `description` from the original dataset in case it is more informative than the field code.\n",
    "\n",
    "The first four columns are the number of times seen vs target for both the node with the code (called \"incl\" for included) and for the parent node. The parent node is called \"succ\" (successor) because the tree is built in reverse time order. Therefore, the successor in the time sequence is the parent in the tree.\n",
    "\n",
    "The next two, `sum_dep` and `n_dep` provide an idea of how deep the code is found on average (== sum_dep/n_dep) in the sequence and can be used in the score when exponential decay is not zero.\n",
    "\n",
    "The next is `edf` (exponential decay factor) and multiplies the final score. E.g. If we set `exponential_decay` to 0.00693 it decays to approx 0.5 in 100 steps because (1- 0.00693)^100 is 0.4988.\n",
    "\n",
    "The next two are the proportion (or lower bound for the confidence interval) of target/seen for both \"incl\" and \"succ\" as explained above.\n",
    "\n",
    "The lift is the quotient of the two and can be log transformed depending on the argument `log_lift`.\n",
    "\n",
    "And the final score is the product `edf*prop_incl*lift`.\n",
    "\n",
    "This score is used by a greedy algorithm to select the codes that are considered for inclusion in decreasing score order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6942ed-9cc5-4b48-a66c-c2fc32f5428c",
   "metadata": {},
   "source": [
    "### Including/excluding codes\n",
    "\n",
    "We can use this dataset to manually include and exclude. Let's suppose we want all the codes with more than 100 targets included so that we don't risk leaving them out.\n",
    "We may also want to exclude every code that has never been part of a target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abc497e6-1244-4b55-8aff-0d9e969ae636",
   "metadata": {},
   "outputs": [],
   "source": [
    "include = ','.join([str(x) for x in top.loc[top['n_incl_target'] > 100, 'code']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2442e90-12ce-407a-a07a-00d5adc36399",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ','.join([str(x) for x in top.loc[top['n_incl_target'] < 1, 'code']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb0cd4-d251-48d4-bc65-19159921c2dc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Important:</b> Make sure you only pass comma separated strings of integers to the arguments <b>force_include</b> and <b>force_exclude</b>. A wrong type may crash your program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e73339-5a26-419a-9b80-ed04cb1b4559",
   "metadata": {},
   "source": [
    "Again, we make a copy and work with the copy since we don't want to modify `events` and the previous `events_copy` has been modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd265ec-49a8-4fc9-9130-15c3fafde434",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_copy = events.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168d949-3c62-4ab8-a215-edf742a3fefc",
   "metadata": {},
   "source": [
    "And we call `optimize_events()` again. This time with the included and excluded codes, 20 steps and trying to introduce 4 codes at each step. We leave the default arguments but set threshold to zero to accept any new code that results in improvement no matter how small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a96d4e0f-c59f-4110-8448-4eaaee46c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, dictionary, top_codes, log = events_copy.optimize_events(train_clips, targets, num_steps = 20, codes_per_step = 4, \n",
    "                                                                  force_include = include, force_exclude = exclude, threshold = 0, lower_bound_p = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4252d68a-d0d3-4601-b9d9-a37fd4ee286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df2d5ad3-2b31-4dc5-b72e-4df98ce26991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing:\n",
      "\n",
      "  1829 codes found in clips.\n",
      "  139 codes removed from internal EventMap.\n",
      "  Current score = 0.845005\n",
      "\n",
      "Step 1 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1638 as 34\n",
      "    Code 1366 as 35\n",
      "    Code 1690 as 36\n",
      "    Code 1740 as 37\n",
      "    ---------------\n",
      "    Score = 0.714938\n",
      "    Best score so far.\n",
      "\n",
      "Step 2 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1456 as 38\n",
      "    Code 481 as 39\n",
      "    Code 980 as 40\n",
      "    Code 1146 as 41\n",
      "    ---------------\n",
      "    Score = 0.719940\n",
      "    Best score so far.\n",
      "\n",
      "Step 3 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 919 as 42\n",
      "    Code 1138 as 43\n",
      "    Code 1398 as 44\n",
      "    Code 1436 as 45\n",
      "    ---------------\n",
      "    Score = 0.717440\n",
      "    Threshold (0.000000) not met (diff = -0.002500)\n",
      "\n",
      "Step 4 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 334 was excluded by the caller\n",
      "    Code 253 was excluded by the caller\n",
      "    Code 1277 as 46\n",
      "    Code 1580 as 47\n",
      "    Code 613 was excluded by the caller\n",
      "    Code 494 as 48\n",
      "    Code 1102 as 49\n",
      "    ---------------\n",
      "    Score = 0.722442\n",
      "    Best score so far.\n",
      "\n",
      "Step 5 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 359 was excluded by the caller\n",
      "    Code 1601 as 50\n",
      "    Code 873 as 51\n",
      "    Code 536 was excluded by the caller\n",
      "    Code 537 as 52\n",
      "    Code 847 as 53\n",
      "    ---------------\n",
      "    Score = 0.722442\n",
      "    Threshold (0.000000) not met (diff = -0.000000)\n",
      "\n",
      "Step 6 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1537 as 54\n",
      "    Code 1331 as 55\n",
      "    Code 1771 as 56\n",
      "    Code 1137 as 57\n",
      "    ---------------\n",
      "    Score = 0.722443\n",
      "    Best score so far.\n",
      "\n",
      "Step 7 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1689 as 58\n",
      "    Code 427 was excluded by the caller\n",
      "    Code 358 was excluded by the caller\n",
      "    Code 1579 as 59\n",
      "    Code 1590 as 60\n",
      "    Code 1365 as 61\n",
      "    ---------------\n",
      "    Score = 0.724947\n",
      "    Best score so far.\n",
      "\n",
      "Step 8 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1589 as 62\n",
      "    Code 1581 as 63\n",
      "    Code 1101 as 64\n",
      "    Code 744 was excluded by the caller\n",
      "    Code 1671 as 65\n",
      "    ---------------\n",
      "    Score = 0.724947\n",
      "    Best score so far.\n",
      "\n",
      "Step 9 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1578 as 66\n",
      "    Code 1670 as 67\n",
      "    Code 918 as 68\n",
      "    Code 1698 as 69\n",
      "    ---------------\n",
      "    Score = 0.727450\n",
      "    Best score so far.\n",
      "\n",
      "Step 10 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1175 as 70\n",
      "    Code 1577 as 71\n",
      "    Code 425 was excluded by the caller\n",
      "    Code 1588 as 72\n",
      "    Code 745 was excluded by the caller\n",
      "    Code 356 was excluded by the caller\n",
      "    Code 917 as 73\n",
      "    ---------------\n",
      "    Score = 0.727450\n",
      "    Best score so far.\n",
      "\n",
      "Step 11 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1652 as 74\n",
      "    Code 1156 as 75\n",
      "    Code 1587 as 76\n",
      "    Code 355 was excluded by the caller\n",
      "    Code 1136 as 77\n",
      "    ---------------\n",
      "    Score = 0.732452\n",
      "    Best score so far.\n",
      "\n",
      "Step 12 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1160 as 78\n",
      "    Code 1168 as 79\n",
      "    Code 357 as 80\n",
      "    Code 1717 as 81\n",
      "    ---------------\n",
      "    Score = 0.734954\n",
      "    Best score so far.\n",
      "\n",
      "Step 13 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1098 as 82\n",
      "    Code 533 was excluded by the caller\n",
      "    Code 1167 as 83\n",
      "    Code 1063 as 84\n",
      "    Code 1495 as 85\n",
      "    ---------------\n",
      "    Score = 0.742459\n",
      "    Best score so far.\n",
      "\n",
      "Step 14 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1716 as 86\n",
      "    Code 1600 as 87\n",
      "    Code 353 as 88\n",
      "    Code 1099 as 89\n",
      "    ---------------\n",
      "    Score = 0.742459\n",
      "    Best score so far.\n",
      "\n",
      "Step 15 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 871 as 90\n",
      "    Code 1097 as 91\n",
      "    Code 907 as 92\n",
      "    Code 1100 as 93\n",
      "    ---------------\n",
      "    Score = 0.744962\n",
      "    Best score so far.\n",
      "\n",
      "Step 16 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 503 was excluded by the caller\n",
      "    Code 352 as 94\n",
      "    Code 1135 as 95\n",
      "    Code 960 as 96\n",
      "    Code 1276 as 97\n",
      "    ---------------\n",
      "    Score = 0.744962\n",
      "    Best score so far.\n",
      "\n",
      "Step 17 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1174 as 98\n",
      "    Code 1748 as 99\n",
      "    Code 354 as 100\n",
      "    Code 1688 as 101\n",
      "    ---------------\n",
      "    Score = 0.744962\n",
      "    Best score so far.\n",
      "\n",
      "Step 18 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1770 as 102\n",
      "    Code 502 was excluded by the caller\n",
      "    Code 1368 as 103\n",
      "    Code 1494 as 104\n",
      "    Code 1060 as 105\n",
      "    ---------------\n",
      "    Score = 0.744962\n",
      "    Best score so far.\n",
      "\n",
      "Step 19 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1829 as 106\n",
      "    Code 906 as 107\n",
      "    Code 760 was excluded by the caller\n",
      "    Code 1739 as 108\n",
      "    Code 1493 as 109\n",
      "    ---------------\n",
      "    Score = 0.747463\n",
      "    Best score so far.\n",
      "\n",
      "Step 20 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1492 as 110\n",
      "    Code 1155 as 111\n",
      "    Code 1586 as 112\n",
      "    Code 475 as 113\n",
      "    ---------------\n",
      "    Score = 0.747463\n",
      "    Best score so far.\n",
      "\n",
      "== F I N A L ==\n",
      "\n",
      "  Final score      = 0.747463\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4a01b-7d8a-46fb-b682-e286457d9f40",
   "metadata": {},
   "source": [
    "### How to apply the dictionary\n",
    "\n",
    "For the sake of this tutorial, we have obtained a dictionary that provides improvement. Of course, in a real case we can iterate and try different things combining the business insight provided by the description with the empirical data from the tree until we get our best results.\n",
    "\n",
    "At the moment, `events_copy` is already optimized and could be used. \n",
    "\n",
    "An alternative method is creating one by copying the original `events` and providing the dictionary to the `copy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e1128ec-bfe6-483e-9f34-20a56688e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_events = events.copy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f0f0c-459e-4eca-b746-42e76cee38e2",
   "metadata": {},
   "source": [
    "And we use this `op_events` to create new clips and fit a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4864fc4f-a7b8-461e-bbab-6d4d93ec3b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 4130 clips totalling 138716 events"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clips = reels.Clips(clients, op_events)\n",
    "intake_train.scan_events(train_clips)\n",
    "\n",
    "train_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68594a86-5999-49e5-9667-e0d3c47dc9b0",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4476e713-f026-41fe-8941-9fb7b919bb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Targets object with 4130 clips\n",
       "\n",
       "Has 400 targets.\n",
       "\n",
       "Is fitted with 4129 clips."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = reels.Targets(train_clips)\n",
    "intake_train_targs.insert_targets(targets)\n",
    "targets.fit(agg = 'longest', depth = 100, as_states = True)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb47c88-2225-492a-8dc4-be8a373c7796",
   "metadata": {},
   "source": [
    "We can also check that the new tree has less nodes overall and many with fewer than one visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4299cb5-4fbe-4728-9a1b-c52628866419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree.size() : 57741\n",
      "\n",
      "num_of_nodes_with_zero_visits : 0\n",
      "num_of_no_targets_one_visit   : 45329\n",
      "num_of_has_target_one_visit   : 6900\n",
      "num_of_no_targets_more_visits : 4949\n",
      "num_of_has_target_more_visits : 563\n",
      "num_of_no_targets_final_node  : 2892\n",
      "num_of_has_target_final_node  : 327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(targets.describe_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1266a4-61ef-441a-b521-b362992bab90",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e12248d9-096e-4c84-9952-6592e48a8acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0    1\n",
      "Obs            \n",
      "0     3477  253\n",
      "1      223  177\n",
      "Accuracy: 0.885, precision: 0.412, f1-score: 0.427\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, train_clips, train_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82be988-e305-4742-ab66-bc6381f51cb8",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ecb3852-c1ed-49f4-ab48-9f485e8ec5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 1037 clips totalling 30266 events"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clips = reels.Clips(clients, op_events)\n",
    "intake_test.scan_events(test_clips)\n",
    "test_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042fd9a-8ea9-4a41-883f-8c3067af7235",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f06842e-e68a-4d73-9464-501bcbc721be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred    0   1\n",
      "Obs          \n",
      "0     858  79\n",
      "1      70  30\n",
      "Accuracy: 0.856, precision: 0.275, f1-score: 0.287\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, test_clips, test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081eed3-0b3f-41f7-a69f-bbca9c932e85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Note that:</b> The optimized model is smaller, builds a smaller tree and generalizes better on unseen data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f275e-9d5e-4d1b-bc7e-faf928ab2439",
   "metadata": {},
   "source": [
    "## Results Interpretation\n",
    "\n",
    "The comparison between the baseline configuration and the optimized event configuration shows clear structural and performance differences.\n",
    "\n",
    "When event discovery is unrestricted, the model builds a larger and more fragmented tree. Many nodes are supported by very few visits, which leads to sparsity and less reliable estimates. This is reflected in a more unbalanced structure and weaker generalization performance.\n",
    "\n",
    "After applying event optimization (e.g., limiting the number of discovered codes), the event space becomes more compact. The resulting tree is smaller, with more balanced node visits and stronger statistical support per split. Performance metrics improve or become more stable across cross-validation folds, indicating better generalization.\n",
    "\n",
    "In practical terms, these results show that reducing event cardinality does not simply shrink the model — it restructures it. The optimized configuration concentrates signal into fewer, more informative event codes, leading to a cleaner model structure and more reliable predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c82f8c-603e-4937-9a9f-6950969173ff",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "By the end of this notebook, you should understand that:\n",
    "\n",
    "* **Event representation strongly influences model behavior.** The way raw codes are defined and limited directly affects tree structure, sparsity, and predictive stability.\n",
    "* **High-cardinality event spaces can hurt generalization.** Too many rare or weakly supported codes lead to fragmented trees and unreliable estimates.\n",
    "* **Event optimization is a structural decision, not just a tuning trick.** Limiting or selecting events reshapes the model and concentrates signal into more informative splits.\n",
    "* **Simpler event spaces can improve both interpretability and performance.** A more compact representation often yields more balanced nodes and more stable cross-validated results.\n",
    "\n",
    "The main lesson is that thoughtful event design is a core part of modeling with `reels`, not a secondary refinement step.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
