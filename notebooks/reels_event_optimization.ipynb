{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a24c8a-dede-4658-bccd-0db87cff718b",
   "metadata": {},
   "source": [
    "# REELS: Event optimizer\n",
    "\n",
    "<img style=\"float: right;\" src=\"images/piece-puzzle.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51496d5b-babc-45be-ad69-1e5ae66f619e",
   "metadata": {},
   "source": [
    "## Prerequisite!!\n",
    "\n",
    "<img style=\"float: left;\" src=\"images/reels_small.png\"> You should complete the **reels_walkthrough** tutorial before starting with this one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb2c80-55e0-4273-86df-ba874e922a8c",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will use some standard packages in this notebook that we include here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81db30db-071c-450d-a5d9-c63a2bed201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time, io\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0b29a-ed11-4ebe-b00d-53b8f25d6d8c",
   "metadata": {},
   "source": [
    "Now, we import reels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79e7af0-9ac6-41b3-ad02-bc10fc2e4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercury.dynamics import reels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea1aee-d4da-44e0-b812-c18e8147df17",
   "metadata": {},
   "source": [
    "Additionally, we can verify that we are using the right version. (This notebook requires at least a version 1.3.1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ac35a4-e588-409d-9ea9-fa9d188891be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mercury.dynamics as md\n",
    "\n",
    "md.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab33474-96c4-4c32-9533-d28df463adfa",
   "metadata": {},
   "source": [
    "## The problem Event Optimization solves!\n",
    "\n",
    "Real datasets possibly have hundreds of millions of transactions, millions of clients and thousands of event codes. Reels usually works just fine in those conditions.\n",
    "\n",
    "On top of that, there may be additional complications:\n",
    "\n",
    "  - Sequences for each client are typically very long (over 100 events).\n",
    "  - We want to predict a target that is extremely unbalanced, like in fraud applications where only 1 in 10,000 clients are targets.\n",
    "\n",
    "Fitting the data will result in way too many sequences being seen just once in the dataset. That will result in extreme overfitting to the point that the model will be of very limited use when applied to unseen data. \n",
    "\n",
    "### What is the \"magical solution\" to that\n",
    "\n",
    "In these conditions, we will typically fit the model with the `as_states` argument of `Targets.fit()` set to true. If, rather than having 30,000 event codes, we could \n",
    "\"magically\" select the 20 codes that are relevant to predicting the target and assign a dummy code to all the rest, we would benefit of both:\n",
    "\n",
    "  - The sequences becoming much shorter (as states)\n",
    "  - The sequences being much less unique\n",
    "  \n",
    "That produces a much smaller tree with many more visits per node that will generalize much better to unseen data.\n",
    "\n",
    "### What is the \"practical solution\" to that\n",
    "\n",
    "Needless to say, it is hard to \"magically\" find **the 20** codes. When we limit the discovery of codes by setting the `max_num_events` argument when constructing `Events` objects, we are only limiting the event to the most **frequently seen** in the dataset, **not necessarily relevant** to any prediction.\n",
    "\n",
    "The good news is: we may find a set of 200 codes that includes 15 of them that works almost as well as the \"perfect\" fit.\n",
    "\n",
    "And we can do that, if we are lucky, by calling an automatic search with default parameters. More likely, it will happen using the tools the **event optimizer** provides to better understand the problem and manually including and excluding sets of codes from the model.\n",
    "\n",
    "### The quest for \"The Dictionary\"\n",
    "\n",
    "Summarizing, we want to find a dictionary that maps thousands of codes in an **Events** object into tenths of relevant codes.\n",
    "\n",
    "This notebook provides examples to understand how to discover and apply that dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ad3c0-88a5-41c1-b15d-0f062f08d1c3",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "This synthetic dataset is \"loosely based\" on a real BBVA web navigation dataset. The original dataset cannot be used in the tutorial for compliance and practical considerations.\n",
    "\n",
    "This synthetic dataset is smaller, simpler and much less unbalanced than the original one. Therefore, it works much better \"out of the box\". Nonetheless, it does improve somewhat with event optimization and, because it is not so easy to auto detect the signal, provides a good basis to understand manual intervention on the optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb36a0c-c1c6-4c0d-aac9-f8a28b331ccd",
   "metadata": {},
   "source": [
    "The following code defines the function `create_datasets()` that uses a Clips object to read the test sequences from it and modifies them at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd6dc82-39cc-4771-abb8-b5faa3efc26d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_chunk(seq, cli, time_ori, max_delay):\n",
    "\tN = len(seq)\n",
    "\n",
    "\temi    = ['click' for _ in range(N)]\n",
    "\tweight = [1 for _ in range(N)]\n",
    "\tclient = [cli for _ in range(N)]\n",
    "\ttimes  = []\n",
    "\tct = time_ori\n",
    "\n",
    "\tfor _ in range(N):\n",
    "\t\tct += random.random()*max_delay\n",
    "\t\ttimes.append(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ct)))\n",
    "\n",
    "\treturn pd.DataFrame(list(zip(emi, seq, weight, client, times)), columns = ['emitter', 'description', 'weight', 'client', 'time'])\n",
    "\n",
    "\n",
    "def modify_chunk(chunk, cli, reduce, mutate):\n",
    "\tN = chunk.shape[0]\n",
    "\n",
    "\tif N > 5:\n",
    "\t\tchunk = chunk.sample(frac = reduce, replace = False)\n",
    "\t\tN = chunk.shape[0]\n",
    "\n",
    "\tchunk.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\tfor _ in range(random.randrange(1, round(2 + mutate*N))):\n",
    "\t\ti = random.randrange(0, N)\n",
    "\t\tj = random.randrange(0, N)\n",
    "\t\tx = chunk.description.at[i] + 1\n",
    "\t\tchunk.description.at[i] = chunk.description.at[j]\n",
    "\t\tchunk.description.at[j] = x\n",
    "\n",
    "\tchunk.client = [cli for _ in range(N)]\n",
    "\n",
    "\treturn chunk\n",
    "\n",
    "\n",
    "def create_datasets(test = False, n_extra = 10, reduce = 0.95, mutate = 0.15):\n",
    "\n",
    "\tevents  = reels.Events()\n",
    "\tclients = reels.Clients()\n",
    "\tclips   = reels.Clips(clients, events)\n",
    "\n",
    "\tchunks = []\n",
    "\ttargs  = None\n",
    "\n",
    "\ttime_ori  = time.mktime(time.strptime('2022-06-01 00:00:01', '%Y-%m-%d %H:%M:%S'))\n",
    "\tmax_delay = 3600\n",
    "\n",
    "\tif test:\n",
    "\t\ti_base = 400\n",
    "\t\ti_top  = 500\n",
    "\telse:\n",
    "\t\ti_base = 0\n",
    "\t\ti_top  = 400\n",
    "\n",
    "\tfor i_cli in range(i_base, i_top):\n",
    "\t\tseq = clips.test_sequence(i_cli, False)\n",
    "\n",
    "\t\tcli = 'n%04i%03i' % (i_cli, 0)\n",
    "\n",
    "\t\tchunk = build_chunk(seq, cli, time_ori, max_delay)\n",
    "\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tfor t in range(1, n_extra):\n",
    "\t\t\tcli\t  = 'n%04i%03i' % (i_cli, t)\n",
    "\t\t\tchunk = modify_chunk(chunk, cli, reduce, mutate)\n",
    "\t\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tseq = clips.test_sequence(i_cli, True)\n",
    "\n",
    "\t\tcli = 't%04i%03i' % (i_cli, 0)\n",
    "\n",
    "\t\tchunk = build_chunk(seq, cli, time_ori, max_delay)\n",
    "\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tct = time.mktime(time.strptime(chunk.time.iloc[-1], '%Y-%m-%d %H:%M:%S'))\n",
    "\t\tct += random.random()*max_delay\n",
    "\t\tct -= random.random()*max_delay\n",
    "\n",
    "\t\tchunk = pd.DataFrame([[cli, time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ct))]], columns = ['client', 'time'])\n",
    "\t\ttargs = chunk if targs is None else pd.concat([targs, chunk])\n",
    "\n",
    "\treturn pd.concat(chunks), targs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f5b907-b165-43f4-86b6-8058d03c559a",
   "metadata": {},
   "source": [
    "## A simple analysis\n",
    "\n",
    "We also copy from the **reels_walkthrough** tutorial the function `analyze()` that will serve to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e88e05-11e0-4b25-af7b-6b96079a9d43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze(targets, clips, targs):\n",
    "    target_hashes = set([clients.hash_client_id(str(id)) for id in targs.client])  # This is the set of all the clients who are targets\n",
    "    Y_obs = [int(hh in target_hashes) for hh in clips.clips_client_hashes()]       # This is the observed target/no_target for all the clients\n",
    "    \n",
    "    T = [t for t in targets.predict_clips(clips)]                                  # These are the predicted times\n",
    "    \n",
    "    t_copy = T.copy()\n",
    "    t_copy.sort()\n",
    "    t_cut = t_copy[sum(Y_obs)]                                                     # t_cut is a cutting time that generates the same number of targets.\n",
    "    \n",
    "    Y_pred = [int(t <= t_cut) for t in T]                                          # This is the predicted target/no_target for all the clients\n",
    "    \n",
    "    x_tab = pd.crosstab(pd.array(Y_obs), pd.array(Y_pred), rownames = ['Obs'], colnames = ['Pred'])\n",
    "    \n",
    "    acc    = metrics.accuracy_score(Y_obs, Y_pred)                                 # We compute basic metrics\n",
    "    prec   = metrics.precision_score(Y_obs, Y_pred)\n",
    "    f1     = metrics.f1_score(Y_obs, Y_pred)\n",
    "\n",
    "    print(x_tab)\n",
    "    print('Accuracy: %.3f, precision: %.3f, f1-score: %.3f' % (acc, prec, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1eb6ad-e805-41c6-bb41-34eb33ee3fff",
   "metadata": {},
   "source": [
    "We create the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b336cb1-da38-444e-ab1b-b0ce0f85b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targs = create_datasets(False)\n",
    "test,  test_targs  = create_datasets(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7681ccad-c997-4a30-9ba0-c56254f0b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emitter</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "      <th>client</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>click</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 00:00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>click</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 00:39:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>click</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 01:32:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>click</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 02:23:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>click</td>\n",
       "      <td>864</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 02:24:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 06:51:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 06:54:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 07:48:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 08:12:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>click</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 08:39:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139783 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   emitter  description  weight    client                 time\n",
       "0    click            1       1  n0000000  2022-06-01 00:00:18\n",
       "1    click           17       1  n0000000  2022-06-01 00:39:57\n",
       "2    click           92       1  n0000000  2022-06-01 01:32:42\n",
       "3    click          227       1  n0000000  2022-06-01 02:23:12\n",
       "4    click          864       1  n0000000  2022-06-01 02:24:58\n",
       "..     ...          ...     ...       ...                  ...\n",
       "14   click          459       1  t0399000  2022-06-01 06:51:43\n",
       "15   click          459       1  t0399000  2022-06-01 06:54:22\n",
       "16   click          459       1  t0399000  2022-06-01 07:48:23\n",
       "17   click          459       1  t0399000  2022-06-01 08:12:49\n",
       "18   click          462       1  t0399000  2022-06-01 08:39:55\n",
       "\n",
       "[139783 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644a8a6a-8c88-4124-9a99-c44a7c306f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0000000</td>\n",
       "      <td>2022-06-01 13:34:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0001000</td>\n",
       "      <td>2022-06-01 21:38:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0002000</td>\n",
       "      <td>2022-06-01 06:27:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0003000</td>\n",
       "      <td>2022-06-01 16:31:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0004000</td>\n",
       "      <td>2022-06-01 08:37:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0395000</td>\n",
       "      <td>2022-06-01 08:47:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0396000</td>\n",
       "      <td>2022-06-02 11:31:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0397000</td>\n",
       "      <td>2022-06-01 03:57:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0398000</td>\n",
       "      <td>2022-06-02 11:28:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 08:35:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      client                 time\n",
       "0   t0000000  2022-06-01 13:34:44\n",
       "0   t0001000  2022-06-01 21:38:58\n",
       "0   t0002000  2022-06-01 06:27:02\n",
       "0   t0003000  2022-06-01 16:31:59\n",
       "0   t0004000  2022-06-01 08:37:26\n",
       "..       ...                  ...\n",
       "0   t0395000  2022-06-01 08:47:41\n",
       "0   t0396000  2022-06-02 11:31:57\n",
       "0   t0397000  2022-06-01 03:57:48\n",
       "0   t0398000  2022-06-02 11:28:20\n",
       "0   t0399000  2022-06-01 08:35:46\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e5ccc-8953-45b3-b1c4-96eae68b44f7",
   "metadata": {},
   "source": [
    "And now, we do a very simple cross-validated fit/predict like we learned in the **reels_walkthrough** tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8502bc31-a710-4f25-971b-e0a2ac2c6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "intake_train       = reels.Intake(train)\n",
    "intake_train_targs = reels.Intake(train_targs)\n",
    "intake_test        = reels.Intake(test)\n",
    "intake_test_targs  = reels.Intake(test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab82fd-9a8c-4f53-aa2b-5cd46bb3547e",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426209b3-659c-415c-9b80-90068911c79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Events object with 1959 events"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = reels.Events(max_num_events = 10000)\n",
    "\n",
    "intake_train.insert_rows(events)\n",
    "intake_test.insert_rows(events)\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d291e74-7ead-48b4-96d6-969023c29442",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9900535-1bbe-4edc-92ad-b0997ad23b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty reels.Clients object (Empty objects select ALL clients.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = reels.Clients()\n",
    "\n",
    "clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876308e-b6d5-43b0-891f-d9bf885ddb64",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a82854c-3b9c-49e3-bf3a-4e7c1a3d8484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 4130 clips totalling 138718 events"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clips = reels.Clips(clients, events)\n",
    "intake_train.scan_events(train_clips)\n",
    "\n",
    "train_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6948f-f6d4-4195-8d20-10c14aac4d63",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2677cf-0498-4866-89a5-83673b0def26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Targets object with 4130 clips\n",
       "\n",
       "Has 400 targets.\n",
       "\n",
       "Is fitted with 4127 clips."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = reels.Targets(train_clips)\n",
    "intake_train_targs.insert_targets(targets)\n",
    "targets.fit(agg = 'longest', depth = 100, as_states = True)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d612c86-41f6-4e87-ab13-84f8afa9af50",
   "metadata": {},
   "source": [
    "We evaluate the prediction over the **training set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81edaf5-3c8a-4fad-b74d-09a754f5f7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0    1\n",
      "Obs            \n",
      "0     3574  156\n",
      "1      155  245\n",
      "Accuracy: 0.925, precision: 0.611, f1-score: 0.612\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, train_clips, train_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101a54c-71dd-4486-a3ab-1e82a0dfae47",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e9f68f-d5e6-4d4c-be3a-f6759286b52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 1037 clips totalling 30816 events"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clips = reels.Clips(clients, events)\n",
    "intake_test.scan_events(test_clips)\n",
    "\n",
    "test_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6ef7-287f-482b-8ea5-4d88a7300d0c",
   "metadata": {},
   "source": [
    "And evaluate the prediction over the **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9c50e30-72dc-438a-ac26-bcdc833389bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred    0   1\n",
      "Obs          \n",
      "0     858  79\n",
      "1      64  36\n",
      "Accuracy: 0.862, precision: 0.313, f1-score: 0.335\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, test_clips, test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c685d-7875-41cb-94d3-2345fc10e58b",
   "metadata": {},
   "source": [
    "## Event Optimization\n",
    "\n",
    "So far, we have trained a rather good model that performs worse on test data, just as expected.\n",
    "\n",
    "We can also check some statistics about the nodes of the fitted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd1fbba-ec83-45ab-aa5e-cea3f96c8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree.size() : 95021\n",
      "\n",
      "num_of_nodes_with_zero_visits : 0\n",
      "num_of_no_targets_one_visit   : 79419\n",
      "num_of_has_target_one_visit   : 10035\n",
      "num_of_no_targets_more_visits : 5133\n",
      "num_of_has_target_more_visits : 434\n",
      "num_of_no_targets_final_node  : 3699\n",
      "num_of_has_target_final_node  : 374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(targets.describe_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42fa5e-9d7b-4f37-8daa-e2830047d287",
   "metadata": {},
   "source": [
    "As we would expect, it has many nodes with only one visit and is unbalanced, but not too much 8:1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf84e4c-45dd-4aa1-9f6f-4d2a5de82d56",
   "metadata": {},
   "source": [
    "In case the original data provides some business insight to us, since we assume the codes are just meaningless numbers,\n",
    "we are going to build a simple dictionary mapping the content to the code. In this case, we map the field `description` (that in our example contains just numbers, but could have been descriptive.)\n",
    "\n",
    "Later we will add a column to our code exploration dataset using this.\n",
    "\n",
    "This can be done by just iterating through the object via `describe_events()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2981ff36-41da-4869-9427-1d310b6ce173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "description = {}\n",
    "for emitter, descr, weight, code in events.describe_events():\n",
    "    description[code] = descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687a09c-6b0d-4c8c-a7b7-7d7bf176ba46",
   "metadata": {},
   "source": [
    "Now, we make a copy of the events dataset and optimize the copy, since the optimization will alter the object and we are just running it to get some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17fe0299-fa0f-4c5d-9b94-4da56d16f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_copy = events.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fddf0-531a-49e1-bd8e-4c806a125e87",
   "metadata": {},
   "source": [
    "Now we run the `optimize_events()` method, just for one iteration and removing exponential decay and the confidence interval.\n",
    "\n",
    "The **exponential decay** is a parameter that allows weighting the score of a code less as it is found deeper in the tree.\n",
    "\n",
    "The **confidence interval** is computed exactly like in `Targets().fit()` and allows computing lift based on the lower bound of a binomial confidence interval for a proportion rather than the proportion itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e6bd37-821a-48f9-b7b3-1a3732c2401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, dictionary, top_codes, log = events_copy.optimize_events(train_clips, targets, num_steps = 1, exp_decay = 0, lower_bound_p = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fc1ec-3414-43df-b348-9968a1e92c10",
   "metadata": {},
   "source": [
    "It returns a tuple of 4 elements:\n",
    "\n",
    " 1. the dictionary that we are not going to use yet, \n",
    " 2. a boolean that is true on success,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21447c77-3a0d-4b41-a01b-f6dcb25b9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d89fd5-56e0-4527-85ba-fc6b2de6be30",
   "metadata": {},
   "source": [
    " 3. a log saved as a string giving us some idea about how the search went,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80c41fb3-0c06-44e5-adad-2a84a0ccf8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing:\n",
      "\n",
      "  1837 codes found in clips.\n",
      "  122 codes removed from internal EventMap.\n",
      "  Current score = 0.857496\n",
      "\n",
      "Step 1 of 1\n",
      "\n",
      "  Trying:\n",
      "    Code 382 as 2\n",
      "    Code 1352 as 3\n",
      "    Code 1279 as 4\n",
      "    Code 492 as 5\n",
      "    Code 1430 as 6\n",
      "    ---------------\n",
      "    Score = 0.077620\n",
      "    Best score so far.\n",
      "\n",
      "== F I N A L ==\n",
      "\n",
      "  Final score      = 0.077620\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562c530-e80e-49c5-a429-049d9819fdfd",
   "metadata": {},
   "source": [
    " 4. and a dataframe with the performance of each code as a string `top_codes`.\n",
    "    \n",
    "We convert it into a pandas dataframe by passing the string to `pd.read_csv()` using an `io.StringIO` and sort it by the column `n_incl_target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "830b0479-1131-4ba3-aafd-a7cb1b3f6a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_succ_seen</th>\n",
       "      <th>n_succ_target</th>\n",
       "      <th>n_incl_seen</th>\n",
       "      <th>n_incl_target</th>\n",
       "      <th>sum_dep</th>\n",
       "      <th>n_dep</th>\n",
       "      <th>edf</th>\n",
       "      <th>prop_succ</th>\n",
       "      <th>prop_incl</th>\n",
       "      <th>lift</th>\n",
       "      <th>score</th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22340</td>\n",
       "      <td>2603</td>\n",
       "      <td>15547</td>\n",
       "      <td>2038</td>\n",
       "      <td>572381</td>\n",
       "      <td>13235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116517</td>\n",
       "      <td>0.131086</td>\n",
       "      <td>0.753789</td>\n",
       "      <td>0.098811</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14774</td>\n",
       "      <td>1814</td>\n",
       "      <td>6970</td>\n",
       "      <td>1019</td>\n",
       "      <td>252661</td>\n",
       "      <td>6009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122783</td>\n",
       "      <td>0.146198</td>\n",
       "      <td>0.784221</td>\n",
       "      <td>0.114652</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12138</td>\n",
       "      <td>1397</td>\n",
       "      <td>5109</td>\n",
       "      <td>656</td>\n",
       "      <td>138171</td>\n",
       "      <td>4041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>0.128401</td>\n",
       "      <td>0.749351</td>\n",
       "      <td>0.096217</td>\n",
       "      <td>20</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16504</td>\n",
       "      <td>1456</td>\n",
       "      <td>8728</td>\n",
       "      <td>552</td>\n",
       "      <td>382241</td>\n",
       "      <td>7465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088221</td>\n",
       "      <td>0.063245</td>\n",
       "      <td>0.540514</td>\n",
       "      <td>0.034185</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10431</td>\n",
       "      <td>1030</td>\n",
       "      <td>3353</td>\n",
       "      <td>310</td>\n",
       "      <td>121537</td>\n",
       "      <td>3001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098744</td>\n",
       "      <td>0.092455</td>\n",
       "      <td>0.660781</td>\n",
       "      <td>0.061092</td>\n",
       "      <td>17</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1207</td>\n",
       "      <td>2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2271</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>589</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1209</td>\n",
       "      <td>4913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1210</td>\n",
       "      <td>2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>5502</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>6009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1837 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_succ_seen  n_succ_target  n_incl_seen  n_incl_target  sum_dep  n_dep  \\\n",
       "0           22340           2603        15547           2038   572381  13235   \n",
       "1           14774           1814         6970           1019   252661   6009   \n",
       "2           12138           1397         5109            656   138171   4041   \n",
       "3           16504           1456         8728            552   382241   7465   \n",
       "4           10431           1030         3353            310   121537   3001   \n",
       "...           ...            ...          ...            ...      ...    ...   \n",
       "1832            1              0            1              0      183      1   \n",
       "1833           51              0           51              0     2271     48   \n",
       "1834            1              0            1              0      174      1   \n",
       "1835            3              0            3              0      503      3   \n",
       "1836           29              0           29              0     5502     29   \n",
       "\n",
       "      edf  prop_succ  prop_incl      lift     score  code description  \n",
       "0     1.0   0.116517   0.131086  0.753789  0.098811     1           1  \n",
       "1     1.0   0.122783   0.146198  0.784221  0.114652     2          17  \n",
       "2     1.0   0.115093   0.128401  0.749351  0.096217    20         349  \n",
       "3     1.0   0.088221   0.063245  0.540514  0.034185    10           2  \n",
       "4     1.0   0.098744   0.092455  0.660781  0.061092    17         350  \n",
       "...   ...        ...        ...       ...       ...   ...         ...  \n",
       "1832  1.0   0.000000   0.000000  0.000000  0.000000  1207        2640  \n",
       "1833  1.0   0.000000   0.000000  0.000000  0.000000   589         564  \n",
       "1834  1.0   0.000000   0.000000  0.000000  0.000000  1209        4913  \n",
       "1835  1.0   0.000000   0.000000  0.000000  0.000000  1210        2657  \n",
       "1836  1.0   0.000000   0.000000  0.000000  0.000000   100        6009  \n",
       "\n",
       "[1837 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = pd.read_csv(io.StringIO(top_codes), sep = '\\t')\n",
    "top['description'] = [description[c] for c in top.code]\n",
    "top.sort_values(by = 'n_incl_target', ascending = False, inplace = True)\n",
    "top.reset_index(drop = True, inplace = True)\n",
    "\n",
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5674b-1cdd-47d1-9c14-2f5209e94e56",
   "metadata": {},
   "source": [
    "NOTE: We have added the field `description` from the original dataset in case it is more informative than the field code.\n",
    "\n",
    "The first four columns are the number of times seen vs target for both the node with the code (called \"incl\" for included) and for the parent node. The parent node is called \"succ\" (successor) because the tree is built in reverse time order. Therefore, the successor in the time sequence is the parent in the tree.\n",
    "\n",
    "The next two, `sum_dep` and `n_dep` provide an idea of how deep the code is found on average (== sum_dep/n_dep) in the sequence and can be used in the score when exponential decay is not zero.\n",
    "\n",
    "The next is `edf` (exponential decay factor) and multiplies the final score. E.g. If we set `exponential_decay` to 0.00693 it decays to approx 0.5 in 100 steps because (1- 0.00693)^100 is 0.4988.\n",
    "\n",
    "The next two are the proportion (or lower bound for the confidence interval) of target/seen for both \"incl\" and \"succ\" as explained above.\n",
    "\n",
    "The lift is the quotient of the two and can be log transformed depending on the argument `log_lift`.\n",
    "\n",
    "And the final score is the product `edf*prop_incl*lift`.\n",
    "\n",
    "This score is used by a greedy algorithm to select the codes that are considered for inclusion in decreasing score order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6942ed-9cc5-4b48-a66c-c2fc32f5428c",
   "metadata": {},
   "source": [
    "### Including/excluding codes\n",
    "\n",
    "We can use this dataset to manually include and exclude. Let's suppose we want all the codes with more than 100 targets included so that we don't risk leaving them out.\n",
    "We may also want to exclude every code that has never been part of a target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abc497e6-1244-4b55-8aff-0d9e969ae636",
   "metadata": {},
   "outputs": [],
   "source": [
    "include = ','.join([str(x) for x in top.loc[top['n_incl_target'] > 100, 'code']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2442e90-12ce-407a-a07a-00d5adc36399",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ','.join([str(x) for x in top.loc[top['n_incl_target'] < 1, 'code']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb0cd4-d251-48d4-bc65-19159921c2dc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Important:</b> Make sure you only pass comma separated strings of integers to the arguments <b>force_include</b> and <b>force_exclude</b>. A wrong type may crash your program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e73339-5a26-419a-9b80-ed04cb1b4559",
   "metadata": {},
   "source": [
    "Again, we make a copy and work with the copy since we don't want to modify `events` and the previous `events_copy` has been modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd265ec-49a8-4fc9-9130-15c3fafde434",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_copy = events.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168d949-3c62-4ab8-a215-edf742a3fefc",
   "metadata": {},
   "source": [
    "And we call `optimize_events()` again. This time with the included and excluded codes, 20 steps and trying to introduce 4 codes at each step. We leave the default arguments but set threshold to zero to accept any new code that results in improvement no matter how small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a96d4e0f-c59f-4110-8448-4eaaee46c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, dictionary, top_codes, log = events_copy.optimize_events(train_clips, targets, num_steps = 20, codes_per_step = 4, \n",
    "                                                                  force_include = include, force_exclude = exclude, threshold = 0, lower_bound_p = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4252d68a-d0d3-4601-b9d9-a37fd4ee286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df2d5ad3-2b31-4dc5-b72e-4df98ce26991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing:\n",
      "\n",
      "  1837 codes found in clips.\n",
      "  122 codes removed from internal EventMap.\n",
      "  Current score = 0.857496\n",
      "\n",
      "Step 1 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 382 as 36\n",
      "    Code 1279 as 37\n",
      "    Code 1352 as 38\n",
      "    Code 492 was excluded by the caller\n",
      "    Code 1448 as 39\n",
      "    ---------------\n",
      "    Score = 0.752453\n",
      "    Best score so far.\n",
      "\n",
      "Step 2 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 979 as 40\n",
      "    Code 1570 as 41\n",
      "    Code 1126 as 42\n",
      "    Code 1386 as 43\n",
      "    ---------------\n",
      "    Score = 0.754955\n",
      "    Best score so far.\n",
      "\n",
      "Step 3 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1430 as 44\n",
      "    Code 1360 as 45\n",
      "    Code 1614 as 46\n",
      "    Code 516 was excluded by the caller\n",
      "    Code 1073 as 47\n",
      "    ---------------\n",
      "    Score = 0.754955\n",
      "    Best score so far.\n",
      "\n",
      "Step 4 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 881 as 48\n",
      "    Code 1590 as 49\n",
      "    Code 827 was excluded by the caller\n",
      "    Code 1172 as 50\n",
      "    Code 1056 as 51\n",
      "    ---------------\n",
      "    Score = 0.754956\n",
      "    Best score so far.\n",
      "\n",
      "Step 5 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 487 as 52\n",
      "    Code 1273 as 53\n",
      "    Code 1681 as 54\n",
      "    Code 1351 as 55\n",
      "    ---------------\n",
      "    Score = 0.759961\n",
      "    Best score so far.\n",
      "\n",
      "Step 6 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1097 as 56\n",
      "    Code 1767 as 57\n",
      "    Code 381 as 58\n",
      "    Code 1125 as 59\n",
      "    ---------------\n",
      "    Score = 0.767463\n",
      "    Best score so far.\n",
      "\n",
      "Step 7 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 443 as 60\n",
      "    Code 1096 as 61\n",
      "    Code 1580 as 62\n",
      "    Code 1680 as 63\n",
      "    ---------------\n",
      "    Score = 0.769966\n",
      "    Best score so far.\n",
      "\n",
      "Step 8 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1612 as 64\n",
      "    Code 1571 as 65\n",
      "    Code 1579 as 66\n",
      "    Code 1569 as 67\n",
      "    ---------------\n",
      "    Score = 0.774968\n",
      "    Best score so far.\n",
      "\n",
      "Step 9 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 379 as 68\n",
      "    Code 1663 as 69\n",
      "    Code 764 as 70\n",
      "    Code 1568 as 71\n",
      "    ---------------\n",
      "    Score = 0.777469\n",
      "    Best score so far.\n",
      "\n",
      "Step 10 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 441 as 72\n",
      "    Code 1689 as 73\n",
      "    Code 1578 as 74\n",
      "    Code 917 as 75\n",
      "    ---------------\n",
      "    Score = 0.777469\n",
      "    Best score so far.\n",
      "\n",
      "Step 11 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1093 as 76\n",
      "    Code 378 as 77\n",
      "    Code 1577 as 78\n",
      "    Code 1662 as 79\n",
      "    ---------------\n",
      "    Score = 0.777469\n",
      "    Best score so far.\n",
      "\n",
      "Step 12 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1155 as 80\n",
      "    Code 916 as 81\n",
      "    Code 1020 as 82\n",
      "    Code 380 as 83\n",
      "    ---------------\n",
      "    Score = 0.777470\n",
      "    Best score so far.\n",
      "\n",
      "Step 13 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 880 as 84\n",
      "    Code 546 was excluded by the caller\n",
      "    Code 440 as 85\n",
      "    Code 1704 as 86\n",
      "    Code 1062 as 87\n",
      "    ---------------\n",
      "    Score = 0.782472\n",
      "    Best score so far.\n",
      "\n",
      "Step 14 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1092 as 88\n",
      "    Code 376 as 89\n",
      "    Code 1483 as 90\n",
      "    Code 1095 as 91\n",
      "    ---------------\n",
      "    Score = 0.782468\n",
      "    Threshold (0.000000) not met (diff = -0.000004)\n",
      "\n",
      "Step 15 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1644 as 92\n",
      "    Code 1703 as 93\n",
      "    Code 1589 as 94\n",
      "    Code 1061 as 95\n",
      "    ---------------\n",
      "    Score = 0.782472\n",
      "    Best score so far.\n",
      "\n",
      "Step 16 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 375 as 96\n",
      "    Code 1094 as 97\n",
      "    Code 1138 as 98\n",
      "    Code 911 as 99\n",
      "    ---------------\n",
      "    Score = 0.782472\n",
      "    Best score so far.\n",
      "\n",
      "Step 17 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1171 as 100\n",
      "    Code 1167 as 101\n",
      "    Code 377 as 102\n",
      "    Code 1158 as 103\n",
      "    ---------------\n",
      "    Score = 0.782472\n",
      "    Best score so far.\n",
      "\n",
      "Step 18 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1588 as 104\n",
      "    Code 1122 as 105\n",
      "    Code 316 was excluded by the caller\n",
      "    Code 1567 as 106\n",
      "    Code 1059 as 107\n",
      "    ---------------\n",
      "    Score = 0.782472\n",
      "    Best score so far.\n",
      "\n",
      "Step 19 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1722 as 108\n",
      "    Code 486 as 109\n",
      "    Code 1166 as 110\n",
      "    Code 1766 as 111\n",
      "    ---------------\n",
      "    Score = 0.782472\n",
      "    Best score so far.\n",
      "\n",
      "Step 20 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 961 as 112\n",
      "    Code 1837 as 113\n",
      "    Code 518 was excluded by the caller\n",
      "    Code 1482 as 114\n",
      "    Code 910 as 115\n",
      "    ---------------\n",
      "    Score = 0.782468\n",
      "    Threshold (0.000000) not met (diff = -0.000004)\n",
      "\n",
      "== F I N A L ==\n",
      "\n",
      "  Final score      = 0.782472\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4a01b-7d8a-46fb-b682-e286457d9f40",
   "metadata": {},
   "source": [
    "### How to apply the dictionary\n",
    "\n",
    "For the sake of this tutorial, we have obtained a dictionary that provides improvement. Of course, in a real case we can iterate and try different things combining the business insight provided by the description with the empirical data from the tree until we get our best results.\n",
    "\n",
    "At the moment, `events_copy` is already optimized and could be used. \n",
    "\n",
    "An alternative method is creating one by copying the original `events` and providing the dictionary to the `copy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e1128ec-bfe6-483e-9f34-20a56688e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_events = events.copy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f0f0c-459e-4eca-b746-42e76cee38e2",
   "metadata": {},
   "source": [
    "And we use this `op_events` to create new clips and fit a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4864fc4f-a7b8-461e-bbab-6d4d93ec3b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 4130 clips totalling 138718 events"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clips = reels.Clips(clients, op_events)\n",
    "intake_train.scan_events(train_clips)\n",
    "\n",
    "train_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68594a86-5999-49e5-9667-e0d3c47dc9b0",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4476e713-f026-41fe-8941-9fb7b919bb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Targets object with 4130 clips\n",
       "\n",
       "Has 400 targets.\n",
       "\n",
       "Is fitted with 4127 clips."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = reels.Targets(train_clips)\n",
    "intake_train_targs.insert_targets(targets)\n",
    "targets.fit(agg = 'longest', depth = 100, as_states = True)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb47c88-2225-492a-8dc4-be8a373c7796",
   "metadata": {},
   "source": [
    "We can also check that the new tree has less nodes overall and many less with one visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4299cb5-4fbe-4728-9a1b-c52628866419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree.size() : 58637\n",
      "\n",
      "num_of_nodes_with_zero_visits : 0\n",
      "num_of_no_targets_one_visit   : 46007\n",
      "num_of_has_target_one_visit   : 7041\n",
      "num_of_no_targets_more_visits : 5002\n",
      "num_of_has_target_more_visits : 587\n",
      "num_of_no_targets_final_node  : 2975\n",
      "num_of_has_target_final_node  : 332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(targets.describe_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1266a4-61ef-441a-b521-b362992bab90",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e12248d9-096e-4c84-9952-6592e48a8acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0    1\n",
      "Obs            \n",
      "0     3516  214\n",
      "1      212  188\n",
      "Accuracy: 0.897, precision: 0.468, f1-score: 0.469\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, train_clips, train_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82be988-e305-4742-ab66-bc6381f51cb8",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ecb3852-c1ed-49f4-ab48-9f485e8ec5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 1037 clips totalling 30343 events"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clips = reels.Clips(clients, op_events)\n",
    "intake_test.scan_events(test_clips)\n",
    "test_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042fd9a-8ea9-4a41-883f-8c3067af7235",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f06842e-e68a-4d73-9464-501bcbc721be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred    0   1\n",
      "Obs          \n",
      "0     867  70\n",
      "1      67  33\n",
      "Accuracy: 0.868, precision: 0.320, f1-score: 0.325\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, test_clips, test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081eed3-0b3f-41f7-a69f-bbca9c932e85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Note that:</b> The optimized model is smaller, builds a smaller tree and generalizes better on unseen data.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
