{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a24c8a-dede-4658-bccd-0db87cff718b",
   "metadata": {},
   "source": [
    "# REELS: Event optimizer\n",
    "\n",
    "<img style=\"float: right;\" src=\"images/piece-puzzle.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51496d5b-babc-45be-ad69-1e5ae66f619e",
   "metadata": {},
   "source": [
    "## Prerequisite!!\n",
    "\n",
    "<img style=\"float: left;\" src=\"images/reels_small.png\"> You should complete the **reels_walkthrough** tutorial before starting with this one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb2c80-55e0-4273-86df-ba874e922a8c",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will use some standard packages in this notebook that we include here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81db30db-071c-450d-a5d9-c63a2bed201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time, io\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0b29a-ed11-4ebe-b00d-53b8f25d6d8c",
   "metadata": {},
   "source": [
    "Now, we import reels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79e7af0-9ac6-41b3-ad02-bc10fc2e4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea1aee-d4da-44e0-b812-c18e8147df17",
   "metadata": {},
   "source": [
    "Additionally, we can verify that we are using the right version. (This notebook requires at least a version 1.3.1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ac35a4-e588-409d-9ea9-fa9d188891be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reels.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab33474-96c4-4c32-9533-d28df463adfa",
   "metadata": {},
   "source": [
    "## The problem Event Optimization solves!\n",
    "\n",
    "Real datasets possibly have hundreds of millions of transactions, millions of clients and thousands of event codes. Reels usually works just fine in those conditions.\n",
    "\n",
    "On top of that, there may be additional complications:\n",
    "\n",
    "  - Sequences for each client are typically very long (over 100 events).\n",
    "  - We want to predict a target that is extremely unbalanced, like in fraud applications where only 1 in 10,000 clients are targets.\n",
    "\n",
    "Fitting the data will result in way too many sequences being seen just once in the dataset. That will result in extreme overfitting to the point that the model will be of very limited use when applied to unseen data. \n",
    "\n",
    "### What is the \"magical solution\" to that\n",
    "\n",
    "In these conditions, we will typically fit the model with the `as_states` argument of `Targets.fit()` set to true. If, rather than having 30,000 event codes, we could \n",
    "\"magically\" select the 20 codes that are relevant to predicting the target and assign a dummy code to all the rest, we would benefit of both:\n",
    "\n",
    "  - The sequences becoming much shorter (as states)\n",
    "  - The sequences being much less unique\n",
    "  \n",
    "That produces a much smaller tree with many more visits per node that will generalize much better to unseen data.\n",
    "\n",
    "### What is the \"practical solution\" to that\n",
    "\n",
    "Needless to say, it is hard to \"magically\" find **the 20** codes. When we limit the discovery of codes by setting the `max_num_events` argument when constructing `Events` objects, we are only limiting the event to the most **frequently seen** in the dataset, **not necessarily relevant** to any prediction.\n",
    "\n",
    "The good news is: we may find a set of 200 codes that includes 15 of them that works almost as well as the \"perfect\" fit.\n",
    "\n",
    "And we can do that, if we are lucky, by calling an automatic search with default parameters. More likely, it will happen using the tools the **event optimizer** provides to better understand the problem and manually including and excluding sets of codes from the model.\n",
    "\n",
    "### The quest for \"The Dictionary\"\n",
    "\n",
    "Summarizing, we want to find a dictionary that maps thousands of codes in an **Events** object into tenths of relevant codes.\n",
    "\n",
    "This notebook provides examples to understand how to discover and apply that dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ad3c0-88a5-41c1-b15d-0f062f08d1c3",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "This synthetic dataset is \"loosely based\" on a real BBVA web navigation dataset. The original dataset cannot be used in the tutorial for compliance and practical considerations.\n",
    "\n",
    "This synthetic dataset is smaller, simpler and much less unbalanced than the original one. Therefore, it works much better \"out of the box\". Nonetheless, it does improve somewhat with event optimization and, because it is not so easy to auto detect the signal, provides a good basis to understand manual intervention on the optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb36a0c-c1c6-4c0d-aac9-f8a28b331ccd",
   "metadata": {},
   "source": [
    "The following code defines the function `create_datasets()` that uses a Clips object to read the test sequences from it and modifies them at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd6dc82-39cc-4771-abb8-b5faa3efc26d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_chunk(seq, cli, time_ori, max_delay):\n",
    "\tN = len(seq)\n",
    "\n",
    "\temi    = ['click' for _ in range(N)]\n",
    "\tweight = [1 for _ in range(N)]\n",
    "\tclient = [cli for _ in range(N)]\n",
    "\ttimes  = []\n",
    "\tct = time_ori\n",
    "\n",
    "\tfor _ in range(N):\n",
    "\t\tct += random.random()*max_delay\n",
    "\t\ttimes.append(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ct)))\n",
    "\n",
    "\treturn pd.DataFrame(list(zip(emi, seq, weight, client, times)), columns = ['emitter', 'description', 'weight', 'client', 'time'])\n",
    "\n",
    "\n",
    "def modify_chunk(chunk, cli, reduce, mutate):\n",
    "\tN = chunk.shape[0]\n",
    "\n",
    "\tif N > 5:\n",
    "\t\tchunk = chunk.sample(frac = reduce, replace = False)\n",
    "\t\tN = chunk.shape[0]\n",
    "\n",
    "\tchunk.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\tfor _ in range(random.randrange(1, round(2 + mutate*N))):\n",
    "\t\ti = random.randrange(0, N)\n",
    "\t\tj = random.randrange(0, N)\n",
    "\t\tx = chunk.description.at[i] + 1\n",
    "\t\tchunk.description.at[i] = chunk.description.at[j]\n",
    "\t\tchunk.description.at[j] = x\n",
    "\n",
    "\tchunk.client = [cli for _ in range(N)]\n",
    "\n",
    "\treturn chunk\n",
    "\n",
    "\n",
    "def create_datasets(test = False, n_extra = 10, reduce = 0.95, mutate = 0.15):\n",
    "\n",
    "\tevents  = reels.Events()\n",
    "\tclients = reels.Clients()\n",
    "\tclips   = reels.Clips(clients, events)\n",
    "\n",
    "\tchunks = []\n",
    "\ttargs  = None\n",
    "\n",
    "\ttime_ori  = time.mktime(time.strptime('2022-06-01 00:00:01', '%Y-%m-%d %H:%M:%S'))\n",
    "\tmax_delay = 3600\n",
    "\n",
    "\tif test:\n",
    "\t\ti_base = 400\n",
    "\t\ti_top  = 500\n",
    "\telse:\n",
    "\t\ti_base = 0\n",
    "\t\ti_top  = 400\n",
    "\n",
    "\tfor i_cli in range(i_base, i_top):\n",
    "\t\tseq = clips.test_sequence(i_cli, False)\n",
    "\n",
    "\t\tcli = 'n%04i%03i' % (i_cli, 0)\n",
    "\n",
    "\t\tchunk = build_chunk(seq, cli, time_ori, max_delay)\n",
    "\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tfor t in range(1, n_extra):\n",
    "\t\t\tcli\t  = 'n%04i%03i' % (i_cli, t)\n",
    "\t\t\tchunk = modify_chunk(chunk, cli, reduce, mutate)\n",
    "\t\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tseq = clips.test_sequence(i_cli, True)\n",
    "\n",
    "\t\tcli = 't%04i%03i' % (i_cli, 0)\n",
    "\n",
    "\t\tchunk = build_chunk(seq, cli, time_ori, max_delay)\n",
    "\t\tchunks.append(chunk)\n",
    "\n",
    "\t\tct = time.mktime(time.strptime(chunk.time.iloc[-1], '%Y-%m-%d %H:%M:%S'))\n",
    "\t\tct += random.random()*max_delay\n",
    "\t\tct -= random.random()*max_delay\n",
    "\n",
    "\t\tchunk = pd.DataFrame([[cli, time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ct))]], columns = ['client', 'time'])\n",
    "\t\ttargs = chunk if targs is None else pd.concat([targs, chunk])\n",
    "\n",
    "\treturn pd.concat(chunks), targs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f5b907-b165-43f4-86b6-8058d03c559a",
   "metadata": {},
   "source": [
    "## A simple analysis\n",
    "\n",
    "We also copy from the **reels_walkthrough** tutorial the function `analyze()` that will serve to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e88e05-11e0-4b25-af7b-6b96079a9d43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze(targets, clips, targs):\n",
    "    target_hashes = set([clients.hash_client_id(str(id)) for id in targs.client])  # This is the set of all the clients who are targets\n",
    "    Y_obs = [int(hh in target_hashes) for hh in clips.clips_client_hashes()]       # This is the observed target/no_target for all the clients\n",
    "    \n",
    "    T = [t for t in targets.predict_clips(clips)]                                  # These are the predicted times\n",
    "    \n",
    "    t_copy = T.copy()\n",
    "    t_copy.sort()\n",
    "    t_cut = t_copy[sum(Y_obs)]                                                     # t_cut is a cutting time that generates the same number of targets.\n",
    "    \n",
    "    Y_pred = [int(t <= t_cut) for t in T]                                          # This is the predicted target/no_target for all the clients\n",
    "    \n",
    "    x_tab = pd.crosstab(pd.array(Y_obs), pd.array(Y_pred), rownames = ['Obs'], colnames = ['Pred'])\n",
    "    \n",
    "    acc    = metrics.accuracy_score(Y_obs, Y_pred)                                 # We compute basic metrics\n",
    "    prec   = metrics.precision_score(Y_obs, Y_pred)\n",
    "    f1     = metrics.f1_score(Y_obs, Y_pred)\n",
    "\n",
    "    print(x_tab)\n",
    "    print('Accuracy: %.3f, precision: %.3f, f1-score: %.3f' % (acc, prec, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1eb6ad-e805-41c6-bb41-34eb33ee3fff",
   "metadata": {},
   "source": [
    "We create the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b336cb1-da38-444e-ab1b-b0ce0f85b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targs = create_datasets(False)\n",
    "test,  test_targs  = create_datasets(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7681ccad-c997-4a30-9ba0-c56254f0b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emitter</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "      <th>client</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>click</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 00:03:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>click</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 00:57:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>click</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 01:40:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>click</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 02:38:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>click</td>\n",
       "      <td>864</td>\n",
       "      <td>1</td>\n",
       "      <td>n0000000</td>\n",
       "      <td>2022-06-01 03:24:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 08:10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 08:51:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 09:49:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>click</td>\n",
       "      <td>459</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 10:00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>click</td>\n",
       "      <td>462</td>\n",
       "      <td>1</td>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 10:27:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139783 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   emitter  description  weight    client                 time\n",
       "0    click            1       1  n0000000  2022-06-01 00:03:38\n",
       "1    click           17       1  n0000000  2022-06-01 00:57:19\n",
       "2    click           92       1  n0000000  2022-06-01 01:40:41\n",
       "3    click          227       1  n0000000  2022-06-01 02:38:29\n",
       "4    click          864       1  n0000000  2022-06-01 03:24:22\n",
       "..     ...          ...     ...       ...                  ...\n",
       "14   click          459       1  t0399000  2022-06-01 08:10:30\n",
       "15   click          459       1  t0399000  2022-06-01 08:51:14\n",
       "16   click          459       1  t0399000  2022-06-01 09:49:47\n",
       "17   click          459       1  t0399000  2022-06-01 10:00:57\n",
       "18   click          462       1  t0399000  2022-06-01 10:27:04\n",
       "\n",
       "[139783 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644a8a6a-8c88-4124-9a99-c44a7c306f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0000000</td>\n",
       "      <td>2022-06-01 14:09:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0001000</td>\n",
       "      <td>2022-06-01 22:34:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0002000</td>\n",
       "      <td>2022-06-01 04:44:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0003000</td>\n",
       "      <td>2022-06-01 17:19:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0004000</td>\n",
       "      <td>2022-06-01 05:18:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0395000</td>\n",
       "      <td>2022-06-01 07:15:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0396000</td>\n",
       "      <td>2022-06-02 07:55:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0397000</td>\n",
       "      <td>2022-06-01 03:38:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0398000</td>\n",
       "      <td>2022-06-02 08:26:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t0399000</td>\n",
       "      <td>2022-06-01 10:29:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      client                 time\n",
       "0   t0000000  2022-06-01 14:09:14\n",
       "0   t0001000  2022-06-01 22:34:48\n",
       "0   t0002000  2022-06-01 04:44:33\n",
       "0   t0003000  2022-06-01 17:19:03\n",
       "0   t0004000  2022-06-01 05:18:26\n",
       "..       ...                  ...\n",
       "0   t0395000  2022-06-01 07:15:36\n",
       "0   t0396000  2022-06-02 07:55:52\n",
       "0   t0397000  2022-06-01 03:38:13\n",
       "0   t0398000  2022-06-02 08:26:15\n",
       "0   t0399000  2022-06-01 10:29:29\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e5ccc-8953-45b3-b1c4-96eae68b44f7",
   "metadata": {},
   "source": [
    "And now, we do a very simple cross-validated fit/predict like we learned in the **reels_walkthrough** tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8502bc31-a710-4f25-971b-e0a2ac2c6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "intake_train       = reels.Intake(train)\n",
    "intake_train_targs = reels.Intake(train_targs)\n",
    "intake_test        = reels.Intake(test)\n",
    "intake_test_targs  = reels.Intake(test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab82fd-9a8c-4f53-aa2b-5cd46bb3547e",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426209b3-659c-415c-9b80-90068911c79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Events object with 1988 events"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = reels.Events(max_num_events = 10000)\n",
    "\n",
    "intake_train.insert_rows(events)\n",
    "intake_test.insert_rows(events)\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d291e74-7ead-48b4-96d6-969023c29442",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9900535-1bbe-4edc-92ad-b0997ad23b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty reels.Clients object (Empty objects select ALL clients.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = reels.Clients()\n",
    "\n",
    "clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876308e-b6d5-43b0-891f-d9bf885ddb64",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a82854c-3b9c-49e3-bf3a-4e7c1a3d8484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 4130 clips totalling 138717 events"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clips = reels.Clips(clients, events)\n",
    "intake_train.scan_events(train_clips)\n",
    "\n",
    "train_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6948f-f6d4-4195-8d20-10c14aac4d63",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2677cf-0498-4866-89a5-83673b0def26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Targets object with 4130 clips\n",
       "\n",
       "Has 400 targets.\n",
       "\n",
       "Is fitted with 4127 clips."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = reels.Targets(train_clips)\n",
    "intake_train_targs.insert_targets(targets)\n",
    "targets.fit(agg = 'longest', depth = 100, as_states = True)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d612c86-41f6-4e87-ab13-84f8afa9af50",
   "metadata": {},
   "source": [
    "We evaluate the prediction over the **training set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81edaf5-3c8a-4fad-b74d-09a754f5f7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0    1\n",
      "Obs            \n",
      "0     3580  150\n",
      "1      146  254\n",
      "Accuracy: 0.928, precision: 0.629, f1-score: 0.632\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, train_clips, train_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101a54c-71dd-4486-a3ab-1e82a0dfae47",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e9f68f-d5e6-4d4c-be3a-f6759286b52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 1037 clips totalling 30822 events"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clips = reels.Clips(clients, events)\n",
    "intake_test.scan_events(test_clips)\n",
    "\n",
    "test_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc6ef7-287f-482b-8ea5-4d88a7300d0c",
   "metadata": {},
   "source": [
    "And evaluate the prediction over the **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9c50e30-72dc-438a-ac26-bcdc833389bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred    0   1\n",
      "Obs          \n",
      "0     864  73\n",
      "1      70  30\n",
      "Accuracy: 0.862, precision: 0.291, f1-score: 0.296\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, test_clips, test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c685d-7875-41cb-94d3-2345fc10e58b",
   "metadata": {},
   "source": [
    "## Event Optimization\n",
    "\n",
    "So far, we have trained a rather good model that performs worse on test data, just as expected.\n",
    "\n",
    "We can also check some statistics about the nodes of the fitted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd1fbba-ec83-45ab-aa5e-cea3f96c8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree.size() : 95477\n",
      "\n",
      "num_of_nodes_with_zero_visits : 0\n",
      "num_of_no_targets_one_visit   : 80080\n",
      "num_of_has_target_one_visit   : 10087\n",
      "num_of_no_targets_more_visits : 4928\n",
      "num_of_has_target_more_visits : 382\n",
      "num_of_no_targets_final_node  : 3699\n",
      "num_of_has_target_final_node  : 367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(targets.describe_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42fa5e-9d7b-4f37-8daa-e2830047d287",
   "metadata": {},
   "source": [
    "As we would expect, it has many nodes with only one visit and is unbalanced, but not too much 8:1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf84e4c-45dd-4aa1-9f6f-4d2a5de82d56",
   "metadata": {},
   "source": [
    "In case the original data provides some business insight to us, since we assume the codes are just meaningless numbers,\n",
    "we are going to build a simple dictionary mapping the content to the code. In this case, we map the field `description` (that in our example contains just numbers, but could have been descriptive.)\n",
    "\n",
    "Later we will add a column to our code exploration dataset using this.\n",
    "\n",
    "This can be done by just iterating through the object via `describe_events()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2981ff36-41da-4869-9427-1d310b6ce173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "description = {}\n",
    "for emitter, descr, weight, code in events.describe_events():\n",
    "    description[code] = descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687a09c-6b0d-4c8c-a7b7-7d7bf176ba46",
   "metadata": {},
   "source": [
    "Now, we make a copy of the events dataset and optimize the copy, since the optimization will alter the object and we are just running it to get some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17fe0299-fa0f-4c5d-9b94-4da56d16f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_copy = events.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fddf0-531a-49e1-bd8e-4c806a125e87",
   "metadata": {},
   "source": [
    "Now we run the `optimize_events()` method, just for one iteration and removing exponential decay and the confidence interval.\n",
    "\n",
    "The **exponential decay** is a parameter that allows weighting the score of a code less as it is found deeper in the tree.\n",
    "\n",
    "The **confidence interval** is computed exactly like in `Targets().fit()` and allows computing lift based on the lower bound of a binomial confidence interval for a proportion rather than the proportion itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e6bd37-821a-48f9-b7b3-1a3732c2401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, dictionary, top_codes, log = events_copy.optimize_events(train_clips, targets, num_steps = 1, exp_decay = 0, lower_bound_p = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fc1ec-3414-43df-b348-9968a1e92c10",
   "metadata": {},
   "source": [
    "It returns a tuple of 4 elements:\n",
    "\n",
    " 1. the dictionary that we are not going to use yet, \n",
    " 2. a boolean that is true on success,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21447c77-3a0d-4b41-a01b-f6dcb25b9444",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d89fd5-56e0-4527-85ba-fc6b2de6be30",
   "metadata": {},
   "source": [
    " 3. a log saved as a string giving us some idea about how the search went,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80c41fb3-0c06-44e5-adad-2a84a0ccf8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing:\n",
      "\n",
      "  1863 codes found in clips.\n",
      "  125 codes removed from internal EventMap.\n",
      "  Current score = 0.865008\n",
      "\n",
      "Step 1 of 1\n",
      "\n",
      "  Trying:\n",
      "    Code 1187 as 2\n",
      "    Code 1158 as 3\n",
      "    Code 1761 as 4\n",
      "    Code 1386 as 5\n",
      "    Code 1604 as 6\n",
      "    ---------------\n",
      "    Score = 0.077619\n",
      "    Best score so far.\n",
      "\n",
      "== F I N A L ==\n",
      "\n",
      "  Final score      = 0.077619\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562c530-e80e-49c5-a429-049d9819fdfd",
   "metadata": {},
   "source": [
    " 4. and a dataframe with the performance of each code as a string `top_codes`.\n",
    "    \n",
    "We convert it into a pandas dataframe by passing the string to `pd.read_csv()` using an `io.StringIO` and sort it by the column `n_incl_target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "830b0479-1131-4ba3-aafd-a7cb1b3f6a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_succ_seen</th>\n",
       "      <th>n_succ_target</th>\n",
       "      <th>n_incl_seen</th>\n",
       "      <th>n_incl_target</th>\n",
       "      <th>sum_dep</th>\n",
       "      <th>n_dep</th>\n",
       "      <th>edf</th>\n",
       "      <th>prop_succ</th>\n",
       "      <th>prop_incl</th>\n",
       "      <th>lift</th>\n",
       "      <th>score</th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22449</td>\n",
       "      <td>2597</td>\n",
       "      <td>15624</td>\n",
       "      <td>2039</td>\n",
       "      <td>577558</td>\n",
       "      <td>13261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115684</td>\n",
       "      <td>0.130504</td>\n",
       "      <td>0.755233</td>\n",
       "      <td>0.098561</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14309</td>\n",
       "      <td>1810</td>\n",
       "      <td>6746</td>\n",
       "      <td>1018</td>\n",
       "      <td>250734</td>\n",
       "      <td>5803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.126494</td>\n",
       "      <td>0.150904</td>\n",
       "      <td>0.785260</td>\n",
       "      <td>0.118499</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12163</td>\n",
       "      <td>1401</td>\n",
       "      <td>5213</td>\n",
       "      <td>653</td>\n",
       "      <td>142270</td>\n",
       "      <td>4184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115185</td>\n",
       "      <td>0.125264</td>\n",
       "      <td>0.735966</td>\n",
       "      <td>0.092190</td>\n",
       "      <td>20</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16904</td>\n",
       "      <td>1464</td>\n",
       "      <td>8801</td>\n",
       "      <td>552</td>\n",
       "      <td>349132</td>\n",
       "      <td>7659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086607</td>\n",
       "      <td>0.062720</td>\n",
       "      <td>0.544760</td>\n",
       "      <td>0.034167</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10741</td>\n",
       "      <td>1120</td>\n",
       "      <td>3262</td>\n",
       "      <td>311</td>\n",
       "      <td>124573</td>\n",
       "      <td>2946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104273</td>\n",
       "      <td>0.095340</td>\n",
       "      <td>0.649368</td>\n",
       "      <td>0.061911</td>\n",
       "      <td>17</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1615</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1220</td>\n",
       "      <td>4329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1918</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1222</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>6698</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1223</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>8819</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1224</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1863 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_succ_seen  n_succ_target  n_incl_seen  n_incl_target  sum_dep  n_dep  \\\n",
       "0           22449           2597        15624           2039   577558  13261   \n",
       "1           14309           1810         6746           1018   250734   5803   \n",
       "2           12163           1401         5213            653   142270   4184   \n",
       "3           16904           1464         8801            552   349132   7659   \n",
       "4           10741           1120         3262            311   124573   2946   \n",
       "...           ...            ...          ...            ...      ...    ...   \n",
       "1858            3              0            3              0     1615      3   \n",
       "1859            6              0            6              0     1918      6   \n",
       "1860           21              0           21              0     6698     21   \n",
       "1861           27              0           27              0     8819     27   \n",
       "1862            1              0            1              0        6      1   \n",
       "\n",
       "      edf  prop_succ  prop_incl      lift     score  code description  \n",
       "0     1.0   0.115684   0.130504  0.755233  0.098561     1           1  \n",
       "1     1.0   0.126494   0.150904  0.785260  0.118499     2          17  \n",
       "2     1.0   0.115185   0.125264  0.735966  0.092190    20         349  \n",
       "3     1.0   0.086607   0.062720  0.544760  0.034167    10           2  \n",
       "4     1.0   0.104273   0.095340  0.649368  0.061911    17         350  \n",
       "...   ...        ...        ...       ...       ...   ...         ...  \n",
       "1858  1.0   0.000000   0.000000  0.000000  0.000000  1220        4329  \n",
       "1859  1.0   0.000000   0.000000  0.000000  0.000000  1222        2744  \n",
       "1860  1.0   0.000000   0.000000  0.000000  0.000000  1223        1956  \n",
       "1861  1.0   0.000000   0.000000  0.000000  0.000000  1224        1135  \n",
       "1862  1.0   0.000000   0.000000  0.000000  0.000000   932         331  \n",
       "\n",
       "[1863 rows x 13 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = pd.read_csv(io.StringIO(top_codes), sep = '\\t')\n",
    "top['description'] = [description[c] for c in top.code]\n",
    "top.sort_values(by = 'n_incl_target', ascending = False, inplace = True)\n",
    "top.reset_index(drop = True, inplace = True)\n",
    "\n",
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5674b-1cdd-47d1-9c14-2f5209e94e56",
   "metadata": {},
   "source": [
    "NOTE: We have added the field `description` from the original dataset in case it is more informative than the field code.\n",
    "\n",
    "The first four columns are the number of times seen vs target for both the node with the code (called \"incl\" for included) and for the parent node. The parent node is called \"succ\" (successor) because the tree is built in reverse time order. Therefore, the successor in the time sequence is the parent in the tree.\n",
    "\n",
    "The next two, `sum_dep` and `n_dep` provide an idea of how deep the code is found on average (== sum_dep/n_dep) in the sequence and can be used in the score when exponential decay is not zero.\n",
    "\n",
    "The next is `edf` (exponential decay factor) and multiplies the final score. E.g. If we set `exponential_decay` to 0.00693 it decays to approx 0.5 in 100 steps because (1- 0.00693)^100 is 0.4988.\n",
    "\n",
    "The next two are the proportion (or lower bound for the confidence interval) of target/seen for both \"incl\" and \"succ\" as explained above.\n",
    "\n",
    "The lift is the quotient of the two and can be log transformed depending on the argument `log_lift`.\n",
    "\n",
    "And the final score is the product `edf*prop_incl*lift`.\n",
    "\n",
    "This score is used by a greedy algorithm to select the codes that are considered for inclusion in decreasing score order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6942ed-9cc5-4b48-a66c-c2fc32f5428c",
   "metadata": {},
   "source": [
    "### Including/excluding codes\n",
    "\n",
    "We can use this dataset to manually include and exclude. Let's suppose we want all the codes with more than 100 targets included so that we don't risk leaving them out.\n",
    "We may also want to exclude every code that has never been part of a target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abc497e6-1244-4b55-8aff-0d9e969ae636",
   "metadata": {},
   "outputs": [],
   "source": [
    "include = ','.join([str(x) for x in top.loc[top['n_incl_target'] > 100, 'code']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2442e90-12ce-407a-a07a-00d5adc36399",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ','.join([str(x) for x in top.loc[top['n_incl_target'] < 1, 'code']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb0cd4-d251-48d4-bc65-19159921c2dc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Important:</b> Make sure you only pass comma separated strings of integers to the arguments <b>force_include</b> and <b>force_exclude</b>. A wrong type may crash your program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e73339-5a26-419a-9b80-ed04cb1b4559",
   "metadata": {},
   "source": [
    "Again, we make a copy and work with the copy since we don't want to modify `events` and the previous `events_copy` has been modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cd265ec-49a8-4fc9-9130-15c3fafde434",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_copy = events.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168d949-3c62-4ab8-a215-edf742a3fefc",
   "metadata": {},
   "source": [
    "And we call `optimize_events()` again. This time with the included and excluded codes, 20 steps and trying to introduce 4 codes at each step. We leave the default arguments but set threshold to zero to accept any new code that results in improvement no matter how small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a96d4e0f-c59f-4110-8448-4eaaee46c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "success, dictionary, top_codes, log = events_copy.optimize_events(train_clips, targets, num_steps = 20, codes_per_step = 4, \n",
    "                                                                  force_include = include, force_exclude = exclude, threshold = 0, lower_bound_p = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4252d68a-d0d3-4601-b9d9-a37fd4ee286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df2d5ad3-2b31-4dc5-b72e-4df98ce26991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing:\n",
      "\n",
      "  1863 codes found in clips.\n",
      "  125 codes removed from internal EventMap.\n",
      "  Current score = 0.865008\n",
      "\n",
      "Step 1 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1158 as 37\n",
      "    Code 1386 as 38\n",
      "    Code 1761 as 39\n",
      "    Code 1187 as 40\n",
      "    ---------------\n",
      "    Score = 0.742444\n",
      "    Best score so far.\n",
      "\n",
      "Step 2 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1604 as 41\n",
      "    Code 995 as 42\n",
      "    Code 1168 as 43\n",
      "    Code 1420 as 44\n",
      "    ---------------\n",
      "    Score = 0.749947\n",
      "    Best score so far.\n",
      "\n",
      "Step 3 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1392 as 45\n",
      "    Code 1115 as 46\n",
      "    Code 881 as 47\n",
      "    Code 1365 as 48\n",
      "    ---------------\n",
      "    Score = 0.747447\n",
      "    Threshold (0.000000) not met (diff = -0.002500)\n",
      "\n",
      "Step 4 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1650 as 49\n",
      "    Code 1712 as 50\n",
      "    Code 1652 as 51\n",
      "    Code 363 was excluded by the caller\n",
      "    Code 1561 as 52\n",
      "    ---------------\n",
      "    Score = 0.749950\n",
      "    Best score so far.\n",
      "\n",
      "Step 5 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1308 as 53\n",
      "    Code 606 was excluded by the caller\n",
      "    Code 1625 as 54\n",
      "    Code 1157 as 55\n",
      "    Code 1313 as 56\n",
      "    ---------------\n",
      "    Score = 0.752451\n",
      "    Best score so far.\n",
      "\n",
      "Step 6 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1800 as 57\n",
      "    Code 386 as 58\n",
      "    Code 385 as 59\n",
      "    Code 1478 as 60\n",
      "    ---------------\n",
      "    Score = 0.757452\n",
      "    Best score so far.\n",
      "\n",
      "Step 7 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1646 as 61\n",
      "    Code 1711 as 62\n",
      "    Code 452 was excluded by the caller\n",
      "    Code 1603 as 63\n",
      "    Code 1615 as 64\n",
      "    ---------------\n",
      "    Score = 0.759955\n",
      "    Best score so far.\n",
      "\n",
      "Step 8 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1114 as 65\n",
      "    Code 1605 as 66\n",
      "    Code 1614 as 67\n",
      "    Code 1738 as 68\n",
      "    ---------------\n",
      "    Score = 0.762457\n",
      "    Best score so far.\n",
      "\n",
      "Step 9 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1602 as 69\n",
      "    Code 1721 as 70\n",
      "    Code 1696 as 71\n",
      "    Code 1208 as 72\n",
      "    ---------------\n",
      "    Score = 0.764958\n",
      "    Best score so far.\n",
      "\n",
      "Step 10 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 927 as 73\n",
      "    Code 1029 as 74\n",
      "    Code 1186 as 75\n",
      "    Code 1156 as 76\n",
      "    ---------------\n",
      "    Score = 0.764958\n",
      "    Best score so far.\n",
      "\n",
      "Step 11 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1613 as 77\n",
      "    Code 1514 as 78\n",
      "    Code 926 as 79\n",
      "    Code 450 was excluded by the caller\n",
      "    Code 1111 as 80\n",
      "    ---------------\n",
      "    Score = 0.769960\n",
      "    Best score so far.\n",
      "\n",
      "Step 12 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 383 was excluded by the caller\n",
      "    Code 1078 as 81\n",
      "    Code 925 as 82\n",
      "    Code 1612 as 83\n",
      "    Code 382 was excluded by the caller\n",
      "    Code 1674 as 84\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Best score so far.\n",
      "\n",
      "Step 13 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 449 was excluded by the caller\n",
      "    Code 1202 as 85\n",
      "    Code 1624 as 86\n",
      "    Code 384 as 87\n",
      "    Code 1077 as 88\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Best score so far.\n",
      "\n",
      "Step 14 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1110 as 89\n",
      "    Code 550 was excluded by the caller\n",
      "    Code 879 as 90\n",
      "    Code 1112 as 91\n",
      "    Code 1623 as 92\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Best score so far.\n",
      "\n",
      "Step 15 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1191 as 93\n",
      "    Code 1201 as 94\n",
      "    Code 1076 as 95\n",
      "    Code 1113 as 96\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Best score so far.\n",
      "\n",
      "Step 16 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 917 as 97\n",
      "    Code 1513 as 98\n",
      "    Code 1511 as 99\n",
      "    Code 1512 as 100\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Best score so far.\n",
      "\n",
      "Step 17 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 380 as 101\n",
      "    Code 523 was excluded by the caller\n",
      "    Code 1477 as 102\n",
      "    Code 1207 as 103\n",
      "    Code 1307 as 104\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Best score so far.\n",
      "\n",
      "Step 18 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1185 as 105\n",
      "    Code 379 was excluded by the caller\n",
      "    Code 970 as 106\n",
      "    Code 1799 as 107\n",
      "    Code 1767 as 108\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Best score so far.\n",
      "\n",
      "Step 19 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 381 as 109\n",
      "    Code 1759 as 110\n",
      "    Code 916 as 111\n",
      "    Code 498 as 112\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Best score so far.\n",
      "\n",
      "Step 20 of 20\n",
      "\n",
      "  Trying:\n",
      "    Code 1863 as 113\n",
      "    Code 1074 as 114\n",
      "    Code 1306 as 115\n",
      "    Code 1710 as 116\n",
      "    ---------------\n",
      "    Score = 0.772462\n",
      "    Threshold (0.000000) not met (diff = -0.000000)\n",
      "\n",
      "== F I N A L ==\n",
      "\n",
      "  Final score      = 0.772462\n"
     ]
    }
   ],
   "source": [
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4a01b-7d8a-46fb-b682-e286457d9f40",
   "metadata": {},
   "source": [
    "### How to apply the dictionary\n",
    "\n",
    "For the sake of this tutorial, we have obtained a dictionary that provides improvement. Of course, in a real case we can iterate and try different things combining the business insight provided by the description with the empirical data from the tree until we get our best results.\n",
    "\n",
    "At the moment, `events_copy` is already optimized and could be used. \n",
    "\n",
    "An alternative method is creating one by copying the original `events` and providing the dictionary to the `copy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e1128ec-bfe6-483e-9f34-20a56688e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_events = events.copy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f0f0c-459e-4eca-b746-42e76cee38e2",
   "metadata": {},
   "source": [
    "And we use this `op_events` to create new clips and fit a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4864fc4f-a7b8-461e-bbab-6d4d93ec3b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 4130 clips totalling 138717 events"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clips = reels.Clips(clients, op_events)\n",
    "intake_train.scan_events(train_clips)\n",
    "\n",
    "train_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68594a86-5999-49e5-9667-e0d3c47dc9b0",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4476e713-f026-41fe-8941-9fb7b919bb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Targets object with 4130 clips\n",
       "\n",
       "Has 400 targets.\n",
       "\n",
       "Is fitted with 4127 clips."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = reels.Targets(train_clips)\n",
    "intake_train_targs.insert_targets(targets)\n",
    "targets.fit(agg = 'longest', depth = 100, as_states = True)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb47c88-2225-492a-8dc4-be8a373c7796",
   "metadata": {},
   "source": [
    "We can also check that the new tree has less nodes overall and many less with one visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4299cb5-4fbe-4728-9a1b-c52628866419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree.size() : 58438\n",
      "\n",
      "num_of_nodes_with_zero_visits : 0\n",
      "num_of_no_targets_one_visit   : 46359\n",
      "num_of_has_target_one_visit   : 7003\n",
      "num_of_no_targets_more_visits : 4548\n",
      "num_of_has_target_more_visits : 528\n",
      "num_of_no_targets_final_node  : 2928\n",
      "num_of_has_target_final_node  : 328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(targets.describe_tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1266a4-61ef-441a-b521-b362992bab90",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e12248d9-096e-4c84-9952-6592e48a8acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred     0    1\n",
      "Obs            \n",
      "0     3507  223\n",
      "1      220  180\n",
      "Accuracy: 0.893, precision: 0.447, f1-score: 0.448\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, train_clips, train_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82be988-e305-4742-ab66-bc6381f51cb8",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ecb3852-c1ed-49f4-ab48-9f485e8ec5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reels.Clips object with 1037 clips totalling 30384 events"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clips = reels.Clips(clients, op_events)\n",
    "intake_test.scan_events(test_clips)\n",
    "test_clips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042fd9a-8ea9-4a41-883f-8c3067af7235",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f06842e-e68a-4d73-9464-501bcbc721be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred    0   1\n",
      "Obs          \n",
      "0     859  78\n",
      "1      72  28\n",
      "Accuracy: 0.855, precision: 0.264, f1-score: 0.272\n"
     ]
    }
   ],
   "source": [
    "analyze(targets, test_clips, test_targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b081eed3-0b3f-41f7-a69f-bbca9c932e85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Note that:</b> The optimized model is smaller, builds a smaller tree and generalizes better on unseen data.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
